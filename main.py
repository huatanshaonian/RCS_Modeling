"""
ä¸»ç¨‹åºï¼šç”¨äºåŠ è½½æ•°æ®ã€è¿›è¡ŒPODåˆ†è§£å’Œæ¨¡æ€åˆ†æ
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from data_loader import load_parameters, load_rcs_data
from pod_analysis import perform_pod, compute_pod_coeffs, energy_analysis
from model_analysis import visualize_modes, parameter_sensitivity, angle_sensitivity, reconstruct_rcs, \
    predict_rcs_from_parameters, evaluate_test_performance, load_prediction_parameters, generate_rcs_predictions, \
    compare_statistics
from calculatercs import calculate_statistics_from_data

# ä¸´æ—¶ä¿®å¤ï¼šå¤šé‡å¯¼å…¥å°è¯•
try:
    # æ–¹æ¡ˆ1ï¼šå°è¯•ä½¿ç”¨æ–°çš„æ¨¡å—åŒ–ç»“æ„
    try:
        from autoencoder_analysis import perform_autoencoder_analysis, compare_with_pod_results, check_pytorch_availability

        pytorch_info = check_pytorch_availability()
        AUTOENCODER_AVAILABLE = pytorch_info['pytorch']
        print("âœ… ä½¿ç”¨æ–°çš„æ¨¡å—åŒ–è‡ªç¼–ç å™¨ç»“æ„")

    except (ImportError, AttributeError):
        # æ–¹æ¡ˆ2ï¼šå›é€€åˆ°åŸå§‹çš„autoencoder_analysisæ¨¡å—
        from autoencoder_analysis import perform_autoencoder_analysis, compare_with_pod_results, PYTORCH_AVAILABLE

        AUTOENCODER_AVAILABLE = PYTORCH_AVAILABLE
        print("âœ… ä½¿ç”¨åŸå§‹çš„autoencoder_analysisæ¨¡å—")

    if AUTOENCODER_AVAILABLE:
        print(f"ğŸ”¥ PyTorchåŠŸèƒ½å¯ç”¨")
    else:
        print("âŒ PyTorchåŠŸèƒ½ä¸å¯ç”¨")

except ImportError as e:
    print(f"âš ï¸ è‡ªç¼–ç å™¨å¯¼å…¥å¤±è´¥: {e}")
    AUTOENCODER_AVAILABLE = False


    # åˆ›å»ºfallbackå‡½æ•°
    def perform_autoencoder_analysis(*args, **kwargs):
        print("âŒ è‡ªç¼–ç å™¨åŠŸèƒ½ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥PyTorchå®‰è£…")
        return {}


    def compare_with_pod_results(*args, **kwargs):
        print("âŒ è‡ªç¼–ç å™¨å¯¹æ¯”åŠŸèƒ½ä¸å¯ç”¨")
        return


# Windowsç¼–ç è®¾ç½®
import sys
if sys.platform.startswith('win'):
    try:
        # å°è¯•è®¾ç½®UTF-8è¾“å‡º
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except:
        pass

# åœ¨plt.figure()ä¹‹å‰æ·»åŠ ä»¥ä¸‹ä»£ç è®¾ç½®ä¸­æ–‡å­—ä½“
import matplotlib as mpl
mpl.rcParams['font.sans-serif'] = ['SimHei']  # è®¾ç½®ä½¿ç”¨é»‘ä½“
mpl.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·'-'æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜


def main(params_path="../parameter/parameters_sorted.csv",
         rcs_dir="../parameter/csv_output",
         output_dir="./results",
         analyze_freq="both",
         num_models=100,
         num_train = "70,80",
         predict_mode = False,
         param_file = None
         ):
    """
    ä¸»ç¨‹åºï¼Œæ§åˆ¶æ•´ä¸ªåˆ†ææµç¨‹

    å‚æ•°:
    params_path: è®¾è®¡å‚æ•°CSVæ–‡ä»¶è·¯å¾„
    rcs_dir: RCSæ•°æ®CSVæ–‡ä»¶ç›®å½•
    output_dir: åˆ†æç»“æœè¾“å‡ºç›®å½•
    analyze_freq: è¦åˆ†æçš„é¢‘ç‡ ("1.5G", "3G", æˆ– "both")
    num_models: è¦åˆ†æçš„æ¨¡å‹æ•°é‡
    """
    """
       ä¸»ç¨‹åºï¼Œæ§åˆ¶æ•´ä¸ªåˆ†ææµç¨‹
       """
    print(f"è¿›å…¥mainå‡½æ•°ï¼Œæ¥æ”¶åˆ°çš„å‚æ•°:")
    print(f"  params_path: {params_path}")
    print(f"  rcs_dir: {rcs_dir}")
    print(f"  output_dir: {output_dir}")
    print(f"  analyze_freq: {analyze_freq}")
    print(f"  num_models: {num_models}")
    print(f"  num_train: {num_train}")
    print(f"  predict_mode: {predict_mode}")
    print(f"  param_file: {param_file}")

    try:
        # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        os.makedirs(output_dir, exist_ok=True)

        # å¤„ç†è®­ç»ƒé›†å¤§å°å‚æ•° - ç¡®ä¿æ­£ç¡®è§£æ
        print(f"åŸå§‹num_trainå‚æ•°: {num_train}")
        if isinstance(num_train, str) and ',' in num_train:
            train_sizes = [int(n.strip()) for n in num_train.split(',')]
        else:
            try:
                # å¦‚æœæ˜¯å•ä¸ªæ•°å­—(å­—ç¬¦ä¸²æˆ–æ•´æ•°)
                train_sizes = [int(num_train)]
            except (ValueError, TypeError):
                print(f"è­¦å‘Š: æ— æ³•è§£æè®­ç»ƒé›†å¤§å° '{num_train}'ï¼Œä½¿ç”¨é»˜è®¤å€¼80")
                train_sizes = [80]

        print(f"è§£æåçš„è®­ç»ƒé›†å¤§å°åˆ—è¡¨: {train_sizes}")

        print("å¼€å§‹åŠ è½½å‚æ•°æ•°æ®...")
        # åŠ è½½å‚æ•°æ•°æ®
        param_data, param_names = load_parameters(params_path)
        print(f"åŠ è½½äº† {param_data.shape[0]} ä¸ªæ¨¡å‹çš„ {param_data.shape[1]} ä¸ªå‚æ•°")

        # æ ‡å‡†åŒ–å‚æ•°æ•°æ®
        scaler = StandardScaler()
        param_data_scaled = scaler.fit_transform(param_data)

        # åˆ†ææŒ‡å®šé¢‘ç‡çš„æ•°æ®
        if analyze_freq in ["1.5G", "both"]:
            try:
                print("å¼€å§‹åŠ è½½1.5GHz RCSæ•°æ®...")
                # åŠ è½½1.5GHz RCSæ•°æ®
                rcs_data_1p5g, theta_values, phi_values, available_models_1p5g = load_rcs_data(rcs_dir, "1.5G",
                                                                                               num_models=num_models)
                print(f"åŠ è½½äº†1.5GHzä¸‹ {rcs_data_1p5g.shape[0]} ä¸ªæ¨¡å‹çš„RCSæ•°æ®")
                print(
                    f"è§’åº¦èŒƒå›´: theta {min(theta_values)}Â° åˆ° {max(theta_values)}Â°, phi {min(phi_values)}Â° åˆ° {max(phi_values)}Â°")

                # å¯¹RCSæ•°æ®è¿›è¡Œå¯¹æ•°å¤„ç†ï¼Œæ·»åŠ å°å€¼é˜²æ­¢log(0)
                rcs_data_1p5g_db = 10 * np.log10(np.maximum(rcs_data_1p5g, 1e-10))

                print("\nå¼€å§‹åˆ†æ1.5GHz RCSæ•°æ®...")
                analyze_frequency_data(rcs_data_1p5g_db, theta_values, phi_values,
                                       param_data, param_data_scaled,
                                       param_names, "1.5GHz", output_dir,
                                       available_models_1p5g, train_sizes,
                                       predict_mode, param_file)
            except Exception as e:
                print(f"å¤„ç†1.5GHzæ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                import traceback
                traceback.print_exc()

        if analyze_freq in ["3G", "both"]:
            try:
                print("å¼€å§‹åŠ è½½3GHz RCSæ•°æ®...")
                # åŠ è½½3GHz RCSæ•°æ®
                rcs_data_3g, theta_values, phi_values, available_models_3g = load_rcs_data(rcs_dir, "3G",
                                                                                           num_models=num_models)
                print(f"åŠ è½½äº†3GHzä¸‹ {rcs_data_3g.shape[0]} ä¸ªæ¨¡å‹çš„RCSæ•°æ®")

                # å¯¹RCSæ•°æ®è¿›è¡Œå¯¹æ•°å¤„ç†ï¼Œæ·»åŠ å°å€¼é˜²æ­¢log(0)
                rcs_data_3g_db = 10 * np.log10(np.maximum(rcs_data_3g, 1e-10))

                print("\nå¼€å§‹åˆ†æ3GHz RCSæ•°æ®...")
                analyze_frequency_data(rcs_data_3g_db, theta_values, phi_values, param_data, param_data_scaled,
                                       param_names, "3GHz", output_dir, available_models_3g, train_sizes, predict_mode, param_file)
            except Exception as e:
                print(f"å¤„ç†3GHzæ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                import traceback
                traceback.print_exc()

        print("\nPODå’Œæ¨¡æ€åˆ†æå®Œæˆã€‚ç»“æœä¿å­˜åœ¨", output_dir)

    except Exception as e:
        print(f"ç¨‹åºæ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1

    return 0


# åœ¨main.pyçš„analyze_frequency_dataå‡½æ•°ä¸­æ·»åŠ æ¨¡å‹ç´¢å¼•å¤„ç†

def analyze_frequency_data(rcs_data, theta_values, phi_values, param_data, param_data_scaled,
                           param_names, freq_label, output_dir, available_models=None,
                           train_sizes=[90], predict_mode=False, param_file=None):
    """
    åˆ†æç‰¹å®šé¢‘ç‡ä¸‹çš„RCSæ•°æ® - å¢å¼ºç‰ˆ

    å‚æ•°:
    rcs_data: å½¢çŠ¶ä¸º [num_models, num_angles] çš„RCSæ•°æ®
    theta_values: thetaè§’åº¦å€¼
    phi_values: phiè§’åº¦å€¼
    param_data: åŸå§‹å‚æ•°æ•°æ®
    param_data_scaled: æ ‡å‡†åŒ–åçš„å‚æ•°æ•°æ®
    param_names: å‚æ•°åç§°åˆ—è¡¨
    freq_label: é¢‘ç‡æ ‡ç­¾ï¼ˆå¦‚"1.5GHz"æˆ–"3GHz"ï¼‰
    output_dir: è¾“å‡ºç›®å½•
    available_models: å¯ç”¨æ¨¡å‹çš„ç´¢å¼•åˆ—è¡¨
    train_sizes: è®­ç»ƒé›†å¤§å°åˆ—è¡¨
    predict_mode: æ˜¯å¦å¯ç”¨é¢„æµ‹æ¨¡å¼
    param_file: é¢„æµ‹æ¨¡å¼ä¸‹çš„å‚æ•°æ–‡ä»¶è·¯å¾„
    """
    try:
        # å¯¼å…¥è®¡ç®—RCSç»Ÿè®¡æ•°æ®çš„å‡½æ•°
        from calculatercs import calculate_statistics_from_data

        # åˆ›å»ºé¢‘ç‡å¯¹åº”çš„è¾“å‡ºç›®å½•
        freq_dir = os.path.join(output_dir, freq_label)
        os.makedirs(freq_dir, exist_ok=True)

        # ä¿å­˜å¯ç”¨æ¨¡å‹ä¿¡æ¯
        if available_models is not None:
            np.save(os.path.join(freq_dir, "available_models.npy"), np.array(available_models))
            print(f"å¯ç”¨æ¨¡å‹æ•°é‡: {len(available_models)}")

        # å¦‚æœåªæœ‰å‚æ•°æ•°æ®çš„å­é›†å¯ç”¨ï¼Œåˆ™åªä½¿ç”¨ç›¸åº”çš„å‚æ•°æ•°æ®
        if available_models is not None:
            # å°†æ¨¡å‹ç´¢å¼•è½¬æ¢ä¸º0-basedç´¢å¼•ï¼ˆå¯¹åº”æ•°ç»„ç´¢å¼•ï¼‰
            model_indices = [i - 1 for i in available_models]
            param_data_subset = param_data[model_indices]
            param_data_scaled_subset = param_data_scaled[model_indices]
        else:
            param_data_subset = param_data
            param_data_scaled_subset = param_data_scaled

        # å¯¹æ¯ä¸ªè®­ç»ƒé›†å¤§å°è¿›è¡Œå¾ªç¯
        for train_size in train_sizes:
            print(f"\n===== åˆ†æè®­ç»ƒé›†å¤§å°: {train_size} =====")

            # ç¡®ä¿è®­ç»ƒé›†å¤§å°ä¸è¶…è¿‡å¯ç”¨æ¨¡å‹æ•°é‡
            if train_size > rcs_data.shape[0]:
                print(f"è­¦å‘Š: è®­ç»ƒé›†å¤§å° {train_size} è¶…è¿‡äº†å¯ç”¨æ¨¡å‹æ•°é‡ {rcs_data.shape[0]}")
                train_size = rcs_data.shape[0]
                print(f"è°ƒæ•´è®­ç»ƒé›†å¤§å°ä¸º: {train_size}")

            # åˆ›å»ºç‰¹å®šè®­ç»ƒé›†å¤§å°çš„è¾“å‡ºç›®å½•
            train_dir = os.path.join(freq_dir, f"train_{train_size}")
            os.makedirs(train_dir, exist_ok=True)

            # éšæœºåˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
            num_models = rcs_data.shape[0]
            np.random.seed(42)  # ç¡®ä¿ç»“æœå¯é‡å¤
            indices = np.random.permutation(num_models)
            train_indices = indices[:train_size]
            test_indices = indices[train_size:]

            print(f"è®­ç»ƒé›†å¤§å°: {len(train_indices)}, æµ‹è¯•é›†å¤§å°: {len(test_indices)}")

            # è¾“å‡ºè®­ç»ƒé›†ç´¢å¼•
            print(f"\nè®­ç»ƒé›†ç´¢å¼• (å…± {len(train_indices)} ä¸ª):")
            print(train_indices)

            # å¦‚æœavailable_modelsä¸ä¸ºNoneï¼Œè½¬æ¢ä¸ºçœŸå®æ¨¡å‹ç¼–å·
            if available_models is not None:
                real_train_indices = [available_models[i] for i in train_indices]
                real_test_indices = [available_models[i] for i in test_indices]

                print(f"\nè®­ç»ƒé›†çœŸå®æ¨¡å‹ç¼–å· (å…± {len(real_train_indices)} ä¸ª):")
                print(real_train_indices)

                # ä¿å­˜çœŸå®æ¨¡å‹ç¼–å·åˆ°æ–‡ä»¶
                train_indices_file = os.path.join(train_dir, "train_models.txt")
                with open(train_indices_file, 'w') as f:
                    f.write(f"è®­ç»ƒé›†å¤§å°: {train_size}\n")
                    f.write("è®­ç»ƒé›†æ¨¡å‹ç¼–å·:\n")
                    for i, model_idx in enumerate(real_train_indices):
                        f.write(f"{i + 1}. {model_idx}\n")

                test_indices_file = os.path.join(train_dir, "test_models.txt")
                with open(test_indices_file, 'w') as f:
                    f.write(f"æµ‹è¯•é›†å¤§å°: {len(real_test_indices)}\n")
                    f.write("æµ‹è¯•é›†æ¨¡å‹ç¼–å·:\n")
                    for i, model_idx in enumerate(real_test_indices):
                        f.write(f"{i + 1}. {model_idx}\n")

                print(f"è®­ç»ƒé›†å’Œæµ‹è¯•é›†æ¨¡å‹ç¼–å·å·²ä¿å­˜åˆ°:\n  {train_indices_file}\n  {test_indices_file}")
            else:
                # ä¿å­˜æ•°ç»„ç´¢å¼•åˆ°æ–‡ä»¶
                train_indices_file = os.path.join(train_dir, "train_indices.txt")
                with open(train_indices_file, 'w') as f:
                    f.write(f"è®­ç»ƒé›†å¤§å°: {train_size}\n")
                    f.write("è®­ç»ƒé›†ç´¢å¼•:\n")
                    for i, idx in enumerate(train_indices):
                        f.write(f"{i + 1}. {idx}\n")

                test_indices_file = os.path.join(train_dir, "test_indices.txt")
                with open(test_indices_file, 'w') as f:
                    f.write(f"æµ‹è¯•é›†å¤§å°: {len(test_indices)}\n")
                    f.write("æµ‹è¯•é›†ç´¢å¼•:\n")
                    for i, idx in enumerate(test_indices):
                        f.write(f"{i + 1}. {idx}\n")

                print(f"è®­ç»ƒé›†å’Œæµ‹è¯•é›†ç´¢å¼•å·²ä¿å­˜åˆ°:\n  {train_indices_file}\n  {test_indices_file}")

            # è®­ç»ƒé›†ä¿¡æ¯
            if available_models is not None:
                train_df = pd.DataFrame({
                    'Index': train_indices,
                    'Model_Number': [available_models[i] for i in train_indices]
                })
            else:
                train_df = pd.DataFrame({
                    'Index': train_indices
                })
            train_df.to_csv(os.path.join(train_dir, "train_indices.csv"), index=False)

            # æµ‹è¯•é›†ä¿¡æ¯
            if available_models is not None:
                test_df = pd.DataFrame({
                    'Index': test_indices,
                    'Model_Number': [available_models[i] for i in test_indices]
                })
            else:
                test_df = pd.DataFrame({
                    'Index': test_indices
                })
            test_df.to_csv(os.path.join(train_dir, "test_indices.csv"), index=False)

            # å¯è§†åŒ–è®­ç»ƒé›†å’Œæµ‹è¯•é›†åœ¨å‚æ•°ç©ºé—´ä¸­çš„åˆ†å¸ƒ
            if param_data_subset.shape[1] >= 2:  # è‡³å°‘æœ‰ä¸¤ä¸ªå‚æ•°
                plt.figure(figsize=(10, 8))
                plt.scatter(param_data_subset[train_indices, 0], param_data_subset[train_indices, 1],
                            c='blue', marker='o', label='è®­ç»ƒé›†')
                plt.scatter(param_data_subset[test_indices, 0], param_data_subset[test_indices, 1],
                            c='red', marker='x', label='æµ‹è¯•é›†')
                plt.xlabel(param_names[0])
                plt.ylabel(param_names[1])
                plt.title(f'è®­ç»ƒé›†å’Œæµ‹è¯•é›†åœ¨å‚æ•°ç©ºé—´çš„åˆ†å¸ƒ (è®­ç»ƒé›†å¤§å°: {train_size})')
                plt.legend()
                plt.grid(True, linestyle='--', alpha=0.7)
                plt.savefig(os.path.join(train_dir, "dataset_distribution.png"))
                plt.close()

            # åˆ†ç¦»å‚æ•°æ•°æ®
            param_data_train = param_data_scaled_subset[train_indices]
            param_data_test = param_data_scaled_subset[test_indices] if len(test_indices) > 0 else np.array([])

            # åˆ†ç¦»RCSæ•°æ®
            rcs_data_train = rcs_data[train_indices]
            rcs_data_test = rcs_data[test_indices] if len(test_indices) > 0 else np.array([])

            # ä¿å­˜è®­ç»ƒé›†å’Œæµ‹è¯•é›†ç´¢å¼•
            np.save(os.path.join(train_dir, "train_indices.npy"), train_indices)
            np.save(os.path.join(train_dir, "test_indices.npy"), test_indices)

            # æ‰§è¡ŒPODåˆ†è§£(ä»…ä½¿ç”¨è®­ç»ƒé›†)
            print("æ‰§è¡ŒPODåˆ†è§£(ä»…ä½¿ç”¨è®­ç»ƒé›†)...")
            try:
                phi_modes_train, lambda_values_train, mean_rcs_train = perform_pod(rcs_data_train)

                # èƒ½é‡åˆ†æ
                print("è¿›è¡Œèƒ½é‡åˆ†æ...")
                modes_90, modes_95, modes_99 = energy_analysis(lambda_values_train, train_dir)

                # é€‰æ‹©ä¿ç•™æ¨¡æ€æ•°é‡ï¼ˆè¿™é‡Œé€‰æ‹©95%èƒ½é‡ï¼‰
                r = max(1, min(modes_95, phi_modes_train.shape[1] - 1))  # ç¡®ä¿è‡³å°‘ä¿ç•™1ä¸ªæ¨¡æ€ï¼Œä¸”ä¸è¶…å‡ºèŒƒå›´
                print(f"é€‰æ‹©ä¿ç•™å‰ {r} ä¸ªæ¨¡æ€ï¼Œè¦†ç›–95%èƒ½é‡")

                # ä¿å­˜PODç»“æœ
                np.save(os.path.join(train_dir, "pod_modes.npy"), phi_modes_train)
                np.save(os.path.join(train_dir, "lambda_values.npy"), lambda_values_train)
                np.save(os.path.join(train_dir, "mean_rcs.npy"), mean_rcs_train)
            except Exception as e:
                print(f"PODåˆ†è§£æˆ–èƒ½é‡åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
                # åˆ›å»ºå¤‡ç”¨æ•°æ®ç»§ç»­åç»­åˆ†æ
                r = 1
                continue

            # è®¡ç®—è®­ç»ƒé›†PODç³»æ•°
            try:
                print("è®¡ç®—è®­ç»ƒé›†PODç³»æ•°...")
                pod_coeffs_train = compute_pod_coeffs(rcs_data_train, phi_modes_train[:, :r], mean_rcs_train)
                np.save(os.path.join(train_dir, "pod_coeffs_train.npy"), pod_coeffs_train)
            except Exception as e:
                print(f"è®¡ç®—è®­ç»ƒé›†PODç³»æ•°æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
                continue

            # å¯è§†åŒ–ä¸»è¦æ¨¡æ€
            print("å¯è§†åŒ–ä¸»è¦æ¨¡æ€...")
            try:
                num_modes_to_visualize = min(10, r)  # å¯è§†åŒ–å‰10ä¸ªæ¨¡æ€
                visualize_modes(phi_modes_train[:, :num_modes_to_visualize], theta_values, phi_values, train_dir)
            except Exception as e:
                print(f"æ¨¡æ€å¯è§†åŒ–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                import traceback
                traceback.print_exc()

            # å‚æ•°æ•æ„Ÿæ€§åˆ†æ
            try:
                print("è¿›è¡Œå‚æ•°æ•æ„Ÿæ€§åˆ†æ...")
                parameter_sensitivity(pod_coeffs_train, param_data_train, param_names,
                                      num_modes=num_modes_to_visualize, output_dir=train_dir)
            except Exception as e:
                print(f"å‚æ•°æ•æ„Ÿæ€§åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                import traceback
                traceback.print_exc()

            # è§’åº¦æ•æ„Ÿæ€§åˆ†æ
            try:
                print("è¿›è¡Œè§’åº¦æ•æ„Ÿæ€§åˆ†æ...")
                angle_sensitivity(phi_modes_train[:, :min(5, phi_modes_train.shape[1])],
                                  theta_values, phi_values, train_dir)
            except Exception as e:
                print(f"è§’åº¦æ•æ„Ÿæ€§åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                import traceback
                traceback.print_exc()

            # è®­ç»ƒé›†é‡æ„ä¸éªŒè¯
            try:
                print("è¿›è¡Œè®­ç»ƒé›†RCSé‡æ„ä¸éªŒè¯...")
                recon_dir = os.path.join(train_dir, "reconstruction_train")
                os.makedirs(recon_dir, exist_ok=True)

                r_values = [min(5, r), min(10, r), r]
                r_values = sorted(list(set(r_values)))  # å»é™¤é‡å¤å€¼å¹¶æ’åº
                reconstruct_rcs(rcs_data_train, phi_modes_train, pod_coeffs_train, mean_rcs_train,
                                r_values, theta_values, phi_values, recon_dir)
                # ä½¿ç”¨æœ€ä¼˜æ¨¡æ€æ•°é‡é‡æ„è¿›è¡Œæ€§èƒ½è¯„ä¼°
                reconstructed_train_optimal = np.dot(pod_coeffs_train, phi_modes_train[:, :r].T) + mean_rcs_train

                # è®¡ç®—R^2å’ŒMSEç”¨äºä¸Autoencoderå¯¹æ¯”
                from sklearn.metrics import r2_score, mean_squared_error
                pod_r2 = r2_score(rcs_data_train.flatten(), reconstructed_train_optimal.flatten())
                pod_mse = mean_squared_error(rcs_data_train, reconstructed_train_optimal)

                print(f"PODé‡æ„æ€§èƒ½: R^2 = {pod_r2:.6f}, MSE = {pod_mse:.6f}")

                # ä¿å­˜PODæ€§èƒ½æŒ‡æ ‡ä¾›åç»­ä½¿ç”¨
                pod_performance = {
                    'r2': pod_r2,
                    'mse': pod_mse,
                    'n_modes': r,
                    'pod_coeffs': pod_coeffs_train,
                    'reconstruction_error': np.mean((rcs_data_train - reconstructed_train_optimal) ** 2, axis=1)
                }

                # è®¡ç®—è®­ç»ƒé›†RCSç»Ÿè®¡æ•°æ®
                print("è®¡ç®—è®­ç»ƒé›†RCSç»Ÿè®¡æ•°æ®...")
                n_theta = len(theta_values)
                n_phi = len(phi_values)

                # ä½¿ç”¨æœ€ä¼˜æ¨¡æ€æ•°é‡é‡æ„
                reconstructed_train = np.dot(pod_coeffs_train, phi_modes_train[:, :r].T) + mean_rcs_train

                # è®¡ç®—åŸå§‹å’Œé‡æ„æ•°æ®çš„ç»Ÿè®¡å‚æ•°
                train_stats_original = []
                train_stats_reconstructed = []

                for i in range(min(5, len(train_indices))):  # åªåˆ†æå‰5ä¸ªæ ·æœ¬
                    # é‡å¡‘ä¸º2Dè§’åº¦çŸ©é˜µ
                    original_2d = rcs_data_train[i].reshape(n_theta, n_phi).T
                    reconstructed_2d = reconstructed_train[i].reshape(n_theta, n_phi).T

                    # è®¡ç®—ç»Ÿè®¡å‚æ•°
                    stats_orig = calculate_statistics_from_data(original_2d, theta_values, phi_values, f'Train{i + 1}')
                    stats_recon = calculate_statistics_from_data(reconstructed_2d, theta_values, phi_values,
                                                                 f'Train{i + 1}')

                    train_stats_original.append(stats_orig)
                    train_stats_reconstructed.append(stats_recon)

                # å°†ç»Ÿè®¡æ•°æ®è½¬æ¢ä¸ºDataFrameå¹¶ä¿å­˜
                df_orig = pd.DataFrame(train_stats_original)
                df_recon = pd.DataFrame(train_stats_reconstructed)

                df_orig.to_csv(os.path.join(recon_dir, 'stats_original.csv'), index=False)
                df_recon.to_csv(os.path.join(recon_dir, 'stats_reconstructed.csv'), index=False)

                # æ¯”è¾ƒç»Ÿè®¡å‚æ•°
                compare_statistics(df_orig, df_recon, recon_dir)

            except Exception as e:
                print(f"è®­ç»ƒé›†RCSé‡æ„ä¸éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                import traceback
                traceback.print_exc()

            # Autoencoderåˆ†æ - æ·»åŠ åœ¨PODåˆ†æå®Œæˆåï¼Œæµ‹è¯•é›†åˆ†æå‰
            try:
                if AUTOENCODER_AVAILABLE:
                    print("\n" + "=" * 50)
                    print("å¼€å§‹Autoencoderé™ç»´åˆ†æ...")
                    print("=" * 50)

                    # å‡†å¤‡PODç»“æœç”¨äºå¯¹æ¯”ï¼ˆä½¿ç”¨å®é™…è®¡ç®—çš„æ€§èƒ½æŒ‡æ ‡ï¼‰
                    pod_results = pod_performance

                    # æ‰§è¡ŒAutoencoderåˆ†æ
                    autoencoder_results = perform_autoencoder_analysis(
                        rcs_data=rcs_data,
                        theta_values=theta_values,
                        phi_values=phi_values,
                        param_data=param_data_scaled_subset,
                        param_names=param_names,
                        freq_label=freq_label,
                        output_dir=train_dir,
                        train_indices=train_indices,
                        test_indices=test_indices if len(test_indices) > 0 else None,
                        latent_dims=[5, 10, 15, 20],  # å¯æ ¹æ®éœ€è¦è°ƒæ•´
                        model_types=['standard', 'vae'],
                        device='auto'  # è‡ªåŠ¨é€‰æ‹©æœ€ä½³è®¾å¤‡
                    )

                    # ä¸PODç»“æœå¯¹æ¯”
                    if autoencoder_results:
                        print("\nå¼€å§‹POD vs Autoencoderå¯¹æ¯”åˆ†æ...")
                        compare_with_pod_results(autoencoder_results, pod_results, train_dir)
                        
                        # å°è¯•è¿›è¡Œå¢å¼ºç‰ˆå¯¹æ¯”åˆ†æ
                        try:
                            from enhanced_comparison import enhanced_compare_with_pod_results
                            print("\nå¼€å§‹å¢å¼ºç‰ˆç»¼åˆå¯¹æ¯”åˆ†æ...")
                            enhanced_compare_with_pod_results(autoencoder_results, pod_results, train_dir, train_dir)
                        except Exception as enhanced_error:
                            print(f"å¢å¼ºç‰ˆå¯¹æ¯”åˆ†æå¤±è´¥: {enhanced_error}")
                        
                        print("Autoencoderåˆ†æå®Œæˆï¼")
                    else:
                        print("Autoencoderåˆ†ææœªäº§ç”Ÿæœ‰æ•ˆç»“æœ")

                else:
                    print("\n" + "=" * 50)
                    print("PyTorchä¸å¯ç”¨ï¼Œè·³è¿‡Autoencoderåˆ†æ")
                    print("å¦‚éœ€ä½¿ç”¨AutoencoderåŠŸèƒ½ï¼Œè¯·å®‰è£…PyTorch:")
                    print("pip install torch torchvision torchaudio")
                    print("=" * 50)

            except Exception as e:
                print(f"\nAutoencoderåˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
                print("Autoencoderåˆ†æå¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œå…¶ä»–åˆ†æ...")
            # ===== Autoencoderåˆ†æç»“æŸ =====

            # æµ‹è¯•é›†ä¸Šçš„é¢„æµ‹å’Œåˆ†æ
            if len(test_indices) > 0:
                try:
                    print("åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œé¢„æµ‹å’Œåˆ†æ...")
                    # åˆ›å»ºæµ‹è¯•ç»“æœç›®å½•
                    test_dir = os.path.join(train_dir, "test")
                    os.makedirs(test_dir, exist_ok=True)

                    # åˆ›å»ºæ¨¡å‹å¹¶é¢„æµ‹æµ‹è¯•é›†
                    test_reconstruction, test_pod_coeffs = predict_rcs_from_parameters(
                        rcs_data_train, phi_modes_train[:, :r], mean_rcs_train,
                        param_data_train, param_data_test,
                        os.path.join(test_dir, "model"))

                    # è¯„ä¼°æµ‹è¯•é›†æ€§èƒ½
                    evaluate_test_performance(
                        rcs_data_test, test_reconstruction, theta_values, phi_values,
                        test_dir, calculate_statistics_from_data)

                except Exception as e:
                    print(f"æµ‹è¯•é›†é¢„æµ‹å’Œåˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                    import traceback
                    traceback.print_exc()

            # å¤„ç†é¢„æµ‹æ¨¡å¼
            if predict_mode and param_file is not None:
                try:
                    print("å¯ç”¨é¢„æµ‹æ¨¡å¼ï¼Œæ ¹æ®æŒ‡å®šå‚æ•°é¢„æµ‹RCS...")
                    predict_dir = os.path.join(train_dir, "predictions")
                    os.makedirs(predict_dir, exist_ok=True)

                    # è¯»å–é¢„æµ‹ç”¨çš„å‚æ•°
                    pred_params = load_prediction_parameters(param_file, param_names)

                    if len(pred_params) > 0:
                        # ç”Ÿæˆé¢„æµ‹ç»“æœ
                        predicted_rcs = generate_rcs_predictions(
                            pred_params, param_data_train, pod_coeffs_train,
                            phi_modes_train[:, :r], mean_rcs_train,
                            theta_values, phi_values, predict_dir)

                        print(f"æˆåŠŸé¢„æµ‹ {len(pred_params)} ç»„å‚æ•°çš„RCSæ•°æ®")
                    else:
                        print("æœªèƒ½åŠ è½½æœ‰æ•ˆçš„é¢„æµ‹å‚æ•°")

                except Exception as e:
                    print(f"é¢„æµ‹æ¨¡å¼è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                    import traceback
                    traceback.print_exc()

    except Exception as e:
        print(f"åˆ†æ{freq_label}æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()