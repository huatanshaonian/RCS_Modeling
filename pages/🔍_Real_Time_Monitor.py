#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Real-Time Monitor - å®æ—¶ç›‘æ§é¡µé¢
ç›‘æ§åˆ†æè¿›ç¨‹çš„è¿è¡ŒçŠ¶æ€å’Œèµ„æºä½¿ç”¨æƒ…å†µ
"""

import streamlit as st
import psutil
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import time
import os
from pathlib import Path
import json
from datetime import datetime

st.set_page_config(
    page_title="Real-Time Monitor",
    page_icon="ğŸ”",
    layout="wide"
)

def get_system_info():
    """è·å–ç³»ç»Ÿä¿¡æ¯"""
    return {
        'cpu_percent': psutil.cpu_percent(interval=1),
        'memory': psutil.virtual_memory(),
        'disk': psutil.disk_usage('/'),
        'boot_time': datetime.fromtimestamp(psutil.boot_time())
    }

def find_python_processes():
    """æŸ¥æ‰¾Pythonç›¸å…³è¿›ç¨‹"""
    processes = []
    for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_info', 'cmdline']):
        try:
            if 'python' in proc.info['name'].lower():
                cmdline = ' '.join(proc.info['cmdline']) if proc.info['cmdline'] else ''
                if 'run.py' in cmdline or 'main.py' in cmdline or 'streamlit' in cmdline:
                    processes.append({
                        'pid': proc.info['pid'],
                        'name': proc.info['name'],
                        'cpu_percent': proc.info['cpu_percent'],
                        'memory_mb': proc.info['memory_info'].rss / 1024 / 1024,
                        'cmdline': cmdline[:100] + '...' if len(cmdline) > 100 else cmdline
                    })
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            pass
    return processes

def monitor_log_files():
    """ç›‘æ§æ—¥å¿—æ–‡ä»¶å˜åŒ–"""
    log_files = []
    current_dir = Path('.')
    
    # æŸ¥æ‰¾æœ€è¿‘çš„æ—¥å¿—æ–‡ä»¶
    for log_file in current_dir.glob('*.log'):
        try:
            stat = log_file.stat()
            log_files.append({
                'name': log_file.name,
                'size_mb': stat.st_size / 1024 / 1024,
                'modified': datetime.fromtimestamp(stat.st_mtime),
                'path': str(log_file)
            })
        except:
            pass
    
    return sorted(log_files, key=lambda x: x['modified'], reverse=True)

def check_gpu_status():
    """æ£€æŸ¥GPUçŠ¶æ€"""
    try:
        import torch
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            gpu_info = []
            for i in range(gpu_count):
                props = torch.cuda.get_device_properties(i)
                memory_allocated = torch.cuda.memory_allocated(i) / 1024**3  # GB
                memory_cached = torch.cuda.memory_reserved(i) / 1024**3  # GB
                memory_total = props.total_memory / 1024**3  # GB
                
                gpu_info.append({
                    'id': i,
                    'name': props.name,
                    'memory_allocated': memory_allocated,
                    'memory_cached': memory_cached,
                    'memory_total': memory_total,
                    'utilization': (memory_allocated / memory_total) * 100
                })
            return gpu_info
        else:
            return []
    except ImportError:
        return None

def main():
    st.title("ğŸ” Real-Time System Monitor")
    st.markdown("å®æ—¶ç›‘æ§ç³»ç»Ÿèµ„æºå’Œåˆ†æè¿›ç¨‹çŠ¶æ€")
    
    # åˆ›å»ºæ›´æ–°æ§åˆ¶
    auto_refresh = st.sidebar.checkbox("è‡ªåŠ¨åˆ·æ–°", value=True)
    refresh_interval = st.sidebar.slider("åˆ·æ–°é—´éš”(ç§’)", 1, 10, 3)
    
    if st.sidebar.button("ğŸ”„ ç«‹å³åˆ·æ–°"):
        st.rerun()
    
    # å ä½ç¬¦ç”¨äºåŠ¨æ€æ›´æ–°
    system_placeholder = st.empty()
    process_placeholder = st.empty()
    gpu_placeholder = st.empty()
    logs_placeholder = st.empty()
    
    while True:
        with system_placeholder.container():
            st.subheader("ğŸ’» ç³»ç»Ÿèµ„æºçŠ¶æ€")
            
            system_info = get_system_info()
            
            # åˆ›å»ºæŒ‡æ ‡è¡Œ
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                cpu_color = "normal"
                if system_info['cpu_percent'] > 80:
                    cpu_color = "inverse"
                st.metric(
                    "CPUä½¿ç”¨ç‡", 
                    f"{system_info['cpu_percent']:.1f}%",
                    delta=f"{'âš ï¸ é«˜è´Ÿè½½' if system_info['cpu_percent'] > 80 else 'âœ… æ­£å¸¸'}"
                )
            
            with col2:
                memory = system_info['memory']
                memory_percent = memory.percent
                st.metric(
                    "å†…å­˜ä½¿ç”¨ç‡",
                    f"{memory_percent:.1f}%",
                    delta=f"{memory.used // 1024**3:.1f}GB / {memory.total // 1024**3:.1f}GB"
                )
            
            with col3:
                disk = system_info['disk']
                disk_percent = (disk.used / disk.total) * 100
                st.metric(
                    "ç£ç›˜ä½¿ç”¨ç‡",
                    f"{disk_percent:.1f}%",
                    delta=f"{disk.free // 1024**3:.1f}GB å¯ç”¨"
                )
            
            with col4:
                uptime = datetime.now() - system_info['boot_time']
                st.metric(
                    "ç³»ç»Ÿè¿è¡Œæ—¶é—´",
                    f"{uptime.days}å¤©",
                    delta=f"{uptime.seconds // 3600}å°æ—¶"
                )
            
            # ç³»ç»Ÿèµ„æºå›¾è¡¨
            if st.checkbox("æ˜¾ç¤ºèµ„æºè¶‹åŠ¿å›¾"):
                # è¿™é‡Œå¯ä»¥æ·»åŠ å†å²æ•°æ®æ”¶é›†å’Œè¶‹åŠ¿å›¾
                fig = make_subplots(
                    rows=2, cols=2,
                    subplot_titles=['CPUä½¿ç”¨ç‡', 'å†…å­˜ä½¿ç”¨ç‡', 'ç£ç›˜I/O', 'ç½‘ç»œI/O'],
                    specs=[[{"secondary_y": False}, {"secondary_y": False}],
                           [{"secondary_y": False}, {"secondary_y": False}]]
                )
                
                # æ¨¡æ‹Ÿæ•°æ®ç‚¹
                x_data = list(range(10))
                fig.add_trace(
                    go.Scatter(x=x_data, y=[system_info['cpu_percent']] * 10, 
                              name='CPU', line=dict(color='red')),
                    row=1, col=1
                )
                fig.add_trace(
                    go.Scatter(x=x_data, y=[memory_percent] * 10, 
                              name='Memory', line=dict(color='blue')),
                    row=1, col=2
                )
                
                fig.update_layout(height=400, showlegend=False)
                st.plotly_chart(fig, use_container_width=True)
        
        with process_placeholder.container():
            st.subheader("ğŸ Pythonè¿›ç¨‹ç›‘æ§")
            
            processes = find_python_processes()
            
            if processes:
                import pandas as pd
                df = pd.DataFrame(processes)
                
                # è¿›ç¨‹ç»Ÿè®¡
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("æ´»è·ƒPythonè¿›ç¨‹", len(processes))
                with col2:
                    total_cpu = sum(p['cpu_percent'] for p in processes)
                    st.metric("æ€»CPUä½¿ç”¨", f"{total_cpu:.1f}%")
                with col3:
                    total_memory = sum(p['memory_mb'] for p in processes)
                    st.metric("æ€»å†…å­˜ä½¿ç”¨", f"{total_memory:.1f}MB")
                
                # è¿›ç¨‹è¯¦æƒ…è¡¨
                st.dataframe(
                    df.style.format({
                        'cpu_percent': '{:.1f}%',
                        'memory_mb': '{:.1f}MB'
                    }),
                    use_container_width=True
                )
                
                # å¦‚æœå‘ç°è¿è¡Œåˆ†æçš„è¿›ç¨‹
                analysis_processes = [p for p in processes if 'run.py' in p['cmdline']]
                if analysis_processes:
                    st.success(f"ğŸŸ¢ æ£€æµ‹åˆ° {len(analysis_processes)} ä¸ªåˆ†æè¿›ç¨‹æ­£åœ¨è¿è¡Œ")
                    for proc in analysis_processes:
                        with st.expander(f"è¿›ç¨‹ {proc['pid']} è¯¦æƒ…"):
                            st.code(proc['cmdline'])
                            st.text(f"CPU: {proc['cpu_percent']:.1f}% | å†…å­˜: {proc['memory_mb']:.1f}MB")
            else:
                st.info("æ²¡æœ‰æ£€æµ‹åˆ°ç›¸å…³çš„Pythonè¿›ç¨‹")
        
        with gpu_placeholder.container():
            st.subheader("ğŸ® GPUçŠ¶æ€ç›‘æ§")
            
            gpu_info = check_gpu_status()
            
            if gpu_info is None:
                st.warning("PyTorchæœªå®‰è£…ï¼Œæ— æ³•æ£€æµ‹GPUçŠ¶æ€")
            elif not gpu_info:
                st.info("æœªæ£€æµ‹åˆ°å¯ç”¨çš„CUDA GPU")
            else:
                for gpu in gpu_info:
                    with st.expander(f"GPU {gpu['id']}: {gpu['name']}", expanded=True):
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric("æ˜¾å­˜ä½¿ç”¨", f"{gpu['utilization']:.1f}%")
                        with col2:
                            st.metric("å·²åˆ†é…æ˜¾å­˜", f"{gpu['memory_allocated']:.2f}GB")
                        with col3:
                            st.metric("æ€»æ˜¾å­˜", f"{gpu['memory_total']:.2f}GB")
                        
                        # æ˜¾å­˜ä½¿ç”¨æ¡å½¢å›¾
                        fig = go.Figure(go.Bar(
                            x=['å·²åˆ†é…', 'å·²ç¼“å­˜', 'ç©ºé—²'],
                            y=[gpu['memory_allocated'], 
                               gpu['memory_cached'] - gpu['memory_allocated'],
                               gpu['memory_total'] - gpu['memory_cached']],
                            marker_color=['red', 'orange', 'green']
                        ))
                        fig.update_layout(
                            title=f"GPU {gpu['id']} æ˜¾å­˜åˆ†å¸ƒ",
                            yaxis_title="æ˜¾å­˜ (GB)",
                            height=300
                        )
                        st.plotly_chart(fig, use_container_width=True)
        
        with logs_placeholder.container():
            st.subheader("ğŸ“‹ æ—¥å¿—æ–‡ä»¶ç›‘æ§")
            
            log_files = monitor_log_files()
            
            if log_files:
                for log_file in log_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    with st.expander(f"ğŸ“„ {log_file['name']} ({log_file['size_mb']:.2f}MB)"):
                        st.text(f"æœ€åä¿®æ”¹: {log_file['modified']}")
                        st.text(f"æ–‡ä»¶å¤§å°: {log_file['size_mb']:.2f}MB")
                        
                        # æ˜¾ç¤ºæœ€åå‡ è¡Œ
                        try:
                            with open(log_file['path'], 'r', encoding='utf-8') as f:
                                lines = f.readlines()
                                if lines:
                                    st.text_area(
                                        "æœ€å10è¡Œ:",
                                        ''.join(lines[-10:]),
                                        height=200
                                    )
                        except:
                            st.error("æ— æ³•è¯»å–æ—¥å¿—æ–‡ä»¶")
            else:
                st.info("å½“å‰ç›®å½•ä¸‹æ²¡æœ‰å‘ç°æ—¥å¿—æ–‡ä»¶")
        
        # å¦‚æœä¸æ˜¯è‡ªåŠ¨åˆ·æ–°æ¨¡å¼ï¼Œè·³å‡ºå¾ªç¯
        if not auto_refresh:
            break
        
        # ç­‰å¾…æŒ‡å®šæ—¶é—´ååˆ·æ–°
        time.sleep(refresh_interval)
        st.rerun()

if __name__ == "__main__":
    main()