"""
åŸºäºAutoencoderçš„RCSæ•°æ®é¢„æµ‹æ¨¡å—
ç”¨äºä»è®¾è®¡å‚æ•°é¢„æµ‹RCSæ•°æ®çš„åŠŸèƒ½å®ç°
"""

import os
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression, Lasso
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
import torch
import pickle
import json

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


def create_autoencoder_prediction_models(latent_data, param_data, model_type='rf'):
    """
    åˆ›å»ºä»è®¾è®¡å‚æ•°åˆ°éšç©ºé—´çš„é¢„æµ‹æ¨¡å‹
    
    å‚æ•°:
    latent_data: éšç©ºé—´æ•°æ® [n_samples, latent_dim]
    param_data: è®¾è®¡å‚æ•°æ•°æ® [n_samples, n_params]
    model_type: æ¨¡å‹ç±»å‹ ('rf', 'lr', 'lasso')
    
    è¿”å›:
    models: é¢„æµ‹æ¨¡å‹åˆ—è¡¨ (æ¯ä¸ªéšç©ºé—´ç»´åº¦ä¸€ä¸ªæ¨¡å‹)
    scaler: å‚æ•°æ ‡å‡†åŒ–å™¨
    """
    latent_dim = latent_data.shape[1]
    models = []
    
    # æ ‡å‡†åŒ–å‚æ•°æ•°æ®
    scaler = StandardScaler()
    param_data_scaled = scaler.fit_transform(param_data)
    
    # ä¸ºæ¯ä¸ªéšç©ºé—´ç»´åº¦è®­ç»ƒé¢„æµ‹æ¨¡å‹
    for i in range(latent_dim):
        if model_type == 'rf':
            model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
        elif model_type == 'lr':
            model = LinearRegression()
        elif model_type == 'lasso':
            model = Lasso(alpha=0.1, random_state=42)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
        
        model.fit(param_data_scaled, latent_data[:, i])
        models.append(model)
    
    return models, scaler


def predict_latent_from_parameters(param_data_test, models, scaler):
    """
    ä»è®¾è®¡å‚æ•°é¢„æµ‹éšç©ºé—´è¡¨ç¤º
    
    å‚æ•°:
    param_data_test: æµ‹è¯•å‚æ•°æ•°æ®
    models: é¢„æµ‹æ¨¡å‹åˆ—è¡¨
    scaler: å‚æ•°æ ‡å‡†åŒ–å™¨
    
    è¿”å›:
    predicted_latent: é¢„æµ‹çš„éšç©ºé—´è¡¨ç¤º
    """
    param_data_scaled = scaler.transform(param_data_test)
    latent_dim = len(models)
    predicted_latent = np.zeros((param_data_test.shape[0], latent_dim))
    
    for i, model in enumerate(models):
        predicted_latent[:, i] = model.predict(param_data_scaled)
    
    return predicted_latent


def predict_rcs_from_autoencoder(autoencoder_model, predicted_latent, data_scaler, device):
    """
    ä½¿ç”¨è®­ç»ƒå¥½çš„Autoencoderä»éšç©ºé—´é‡æ„RCSæ•°æ®
    
    å‚æ•°:
    autoencoder_model: è®­ç»ƒå¥½çš„Autoencoderæ¨¡å‹
    predicted_latent: é¢„æµ‹çš„éšç©ºé—´è¡¨ç¤º
    data_scaler: RCSæ•°æ®æ ‡å‡†åŒ–å™¨
    device: è®¡ç®—è®¾å¤‡
    
    è¿”å›:
    reconstructed_rcs: é‡æ„çš„RCSæ•°æ®
    """
    autoencoder_model.eval()
    
    with torch.no_grad():
        latent_tensor = torch.from_numpy(predicted_latent.astype(np.float32)).to(device)
        
        # ä½¿ç”¨è§£ç å™¨é‡æ„æ•°æ®
        if hasattr(autoencoder_model, 'decode'):
            # VAEæ¨¡å‹
            reconstructed_tensor = autoencoder_model.decode(latent_tensor)
        else:
            # æ ‡å‡†Autoencoder - ä½¿ç”¨è§£ç å™¨éƒ¨åˆ†
            reconstructed_tensor = autoencoder_model.decoder(latent_tensor)
        
        reconstructed_data = reconstructed_tensor.cpu().numpy()
    
    # é€†æ ‡å‡†åŒ–
    reconstructed_rcs = data_scaler.inverse_transform(reconstructed_data)
    
    return reconstructed_rcs


def create_autoencoder_prediction_pipeline(config_results, param_data_train, param_data_test, output_dir):
    """
    åˆ›å»ºå®Œæ•´çš„Autoencoderé¢„æµ‹æµæ°´çº¿
    
    å‚æ•°:
    config_results: Autoencoderé…ç½®ç»“æœ
    param_data_train: è®­ç»ƒé›†å‚æ•°æ•°æ®
    param_data_test: æµ‹è¯•é›†å‚æ•°æ•°æ®
    output_dir: è¾“å‡ºç›®å½•
    
    è¿”å›:
    prediction_results: é¢„æµ‹ç»“æœå­—å…¸
    """
    os.makedirs(output_dir, exist_ok=True)
    
    prediction_results = {}
    
    for config_name, results in config_results.items():
        print(f"\nä¸ºé…ç½® {config_name} åˆ›å»ºé¢„æµ‹æ¨¡å‹...")
        
        config_dir = os.path.join(output_dir, config_name)
        os.makedirs(config_dir, exist_ok=True)
        
        # è·å–è®­ç»ƒæ•°æ®
        train_latent = results['train_latent']
        autoencoder_model = results['model']
        data_scaler = results['scaler']
        
        # åˆ›å»ºå‚æ•°åˆ°éšç©ºé—´çš„é¢„æµ‹æ¨¡å‹
        try:
            models, param_scaler = create_autoencoder_prediction_models(
                train_latent, param_data_train, model_type='rf'
            )
            
            # é¢„æµ‹æµ‹è¯•é›†éšç©ºé—´
            predicted_latent = predict_latent_from_parameters(
                param_data_test, models, param_scaler
            )
            
            # ä»éšç©ºé—´é‡æ„RCSæ•°æ®
            device = next(autoencoder_model.parameters()).device
            reconstructed_rcs = predict_rcs_from_autoencoder(
                autoencoder_model, predicted_latent, data_scaler, device
            )
            
            # å¦‚æœæœ‰çœŸå®çš„æµ‹è¯•é›†æ•°æ®ï¼Œè®¡ç®—é¢„æµ‹æ€§èƒ½
            performance_metrics = {}
            if 'test_latent' in results and 'test_recon' in results:
                true_latent = results['test_latent']
                true_rcs = results['test_recon']
                
                # éšç©ºé—´é¢„æµ‹æ€§èƒ½
                latent_mse = mean_squared_error(true_latent, predicted_latent)
                latent_r2 = r2_score(true_latent, predicted_latent)
                
                # RCSé‡æ„é¢„æµ‹æ€§èƒ½
                rcs_mse = mean_squared_error(true_rcs, reconstructed_rcs)
                rcs_r2 = r2_score(true_rcs, reconstructed_rcs)
                
                performance_metrics = {
                    'latent_mse': latent_mse,
                    'latent_r2': latent_r2,
                    'rcs_mse': rcs_mse,
                    'rcs_r2': rcs_r2
                }
                
                print(f"  éšç©ºé—´é¢„æµ‹ - MSE: {latent_mse:.6f}, RÂ²: {latent_r2:.6f}")
                print(f"  RCSé‡æ„é¢„æµ‹ - MSE: {rcs_mse:.6f}, RÂ²: {rcs_r2:.6f}")
            
            # ä¿å­˜é¢„æµ‹æ¨¡å‹å’Œç»“æœ
            model_file = os.path.join(config_dir, 'prediction_models.pkl')
            with open(model_file, 'wb') as f:
                pickle.dump({
                    'models': models,
                    'param_scaler': param_scaler,
                    'model_type': 'rf'
                }, f)
            
            # ä¿å­˜é¢„æµ‹ç»“æœ
            np.save(os.path.join(config_dir, 'predicted_latent.npy'), predicted_latent)
            np.save(os.path.join(config_dir, 'reconstructed_rcs.npy'), reconstructed_rcs)
            
            # å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§
            visualize_feature_importance(models, config_name, config_dir)
            
            prediction_results[config_name] = {
                'predicted_latent': predicted_latent,
                'reconstructed_rcs': reconstructed_rcs,
                'performance': performance_metrics,
                'models': models,
                'param_scaler': param_scaler
            }
            
            print(f"  é…ç½® {config_name} é¢„æµ‹æ¨¡å‹åˆ›å»ºå®Œæˆ")
            
        except Exception as e:
            print(f"  é…ç½® {config_name} é¢„æµ‹æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    return prediction_results


def visualize_feature_importance(models, config_name, output_dir):
    """
    å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§
    
    å‚æ•°:
    models: é¢„æµ‹æ¨¡å‹åˆ—è¡¨
    config_name: é…ç½®åç§°
    output_dir: è¾“å‡ºç›®å½•
    """
    latent_dim = len(models)
    
    # åªæœ‰RandomForestæ¨¡å‹æœ‰feature_importances_å±æ€§
    if hasattr(models[0], 'feature_importances_'):
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle(f'{config_name} - å‚æ•°é‡è¦æ€§åˆ†æ', fontsize=16)
        
        # æ˜¾ç¤ºå‰4ä¸ªéšç©ºé—´ç»´åº¦çš„é‡è¦æ€§
        for i in range(min(4, latent_dim)):
            row, col = i // 2, i % 2
            ax = axes[row, col] if latent_dim > 1 else axes
            
            importance = models[i].feature_importances_
            param_indices = range(len(importance))
            
            bars = ax.bar(param_indices, importance)
            ax.set_title(f'éšç©ºé—´ç»´åº¦ {i+1} çš„å‚æ•°é‡è¦æ€§')
            ax.set_xlabel('å‚æ•°ç´¢å¼•')
            ax.set_ylabel('é‡è¦æ€§')
            ax.grid(True, alpha=0.3)
            
            # æ ‡æ³¨æœ€é‡è¦çš„å‚æ•°
            max_idx = np.argmax(importance)
            ax.annotate(f'æœ€é‡è¦: å‚æ•°{max_idx+1}', 
                       xy=(max_idx, importance[max_idx]),
                       xytext=(max_idx, importance[max_idx] + 0.02),
                       arrowprops=dict(arrowstyle='->', color='red'),
                       fontsize=10, ha='center')
        
        # éšè—å¤šä½™çš„å­å›¾
        for i in range(latent_dim, 4):
            row, col = i // 2, i % 2
            axes[row, col].set_visible(False)
        
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, 'parameter_importance.png'), dpi=300, bbox_inches='tight')
        plt.close()


def save_prediction_summary(prediction_results, output_dir):
    """
    ä¿å­˜é¢„æµ‹ç»“æœæ‘˜è¦
    
    å‚æ•°:
    prediction_results: é¢„æµ‹ç»“æœå­—å…¸
    output_dir: è¾“å‡ºç›®å½•
    """
    from datetime import datetime
    
    summary = {
        'created_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'prediction_method': 'Random Forest -> Autoencoder Decoder',
        'configurations': []
    }
    
    for config_name, results in prediction_results.items():
        config_summary = {
            'config_name': config_name,
            'latent_dim': results['predicted_latent'].shape[1],
            'test_samples': results['predicted_latent'].shape[0]
        }
        
        if 'performance' in results and results['performance']:
            config_summary.update(results['performance'])
        
        summary['configurations'].append(config_summary)
    
    # ä¿å­˜JSONæ‘˜è¦
    summary_file = os.path.join(output_dir, 'prediction_summary.json')
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“Š é¢„æµ‹ç»“æœæ‘˜è¦å·²ä¿å­˜: {summary_file}")


def load_prediction_models(config_dir):
    """
    åŠ è½½å·²ä¿å­˜çš„é¢„æµ‹æ¨¡å‹
    
    å‚æ•°:
    config_dir: é…ç½®ç›®å½•
    
    è¿”å›:
    models: é¢„æµ‹æ¨¡å‹åˆ—è¡¨
    param_scaler: å‚æ•°æ ‡å‡†åŒ–å™¨
    """
    model_file = os.path.join(config_dir, 'prediction_models.pkl')
    
    if os.path.exists(model_file):
        with open(model_file, 'rb') as f:
            data = pickle.load(f)
        return data['models'], data['param_scaler']
    else:
        raise FileNotFoundError(f"é¢„æµ‹æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_file}")


if __name__ == "__main__":
    print("Autoencoderé¢„æµ‹æ¨¡å—æµ‹è¯•")
    print("è¯¥æ¨¡å—æä¾›ä»¥ä¸‹åŠŸèƒ½:")
    print("- ä»è®¾è®¡å‚æ•°é¢„æµ‹éšç©ºé—´è¡¨ç¤º")
    print("- ä½¿ç”¨Autoencoderè§£ç å™¨é‡æ„RCSæ•°æ®")  
    print("- åˆ›å»ºå®Œæ•´çš„é¢„æµ‹æµæ°´çº¿")
    print("- å¯è§†åŒ–å‚æ•°é‡è¦æ€§åˆ†æ")