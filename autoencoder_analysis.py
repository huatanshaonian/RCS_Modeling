"""
åŸºäºæ·±åº¦å­¦ä¹ Autoencoderçš„RCSæ•°æ®é™ç»´åˆ†ææ¨¡å—
ä½¿ç”¨PyTorchå®ç°å˜åˆ†è‡ªç¼–ç å™¨(VAE)å’Œæ ‡å‡†è‡ªç¼–ç å™¨(AE)ç”¨äºRCSæ•°æ®é™ç»´

é‡æ„åçš„ä¸»åˆ†ææ¨¡å—ï¼Œåè°ƒå„ä¸ªå­æ¨¡å—çš„åŠŸèƒ½
"""

import os
import numpy as np
from sklearn.preprocessing import StandardScaler
import torch
from torch.utils.data import TensorDataset
import warnings

warnings.filterwarnings('ignore')

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
try:
    from .autoencoder_models import StandardAutoencoder, VariationalAutoencoder
    from .autoencoder_training import train_autoencoder, evaluate_model
    from .autoencoder_utils import (
        validate_data_integrity, get_device_info, get_optimal_batch_size,
        create_optimized_data_loaders, log_info, cleanup_gpu_memory, PYTORCH_AVAILABLE
    )
    from .autoencoder_visualization import (
        plot_training_history, visualize_latent_space, analyze_reconstruction_error,
        generate_comparison_analysis, compare_with_pod_results
    )
except ImportError:
    # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ç»å¯¹å¯¼å…¥
    from autoencoder_models import StandardAutoencoder, VariationalAutoencoder
    from autoencoder_training import train_autoencoder, evaluate_model
    from autoencoder_utils import (
        validate_data_integrity, get_device_info, get_optimal_batch_size,
        create_optimized_data_loaders, log_info, cleanup_gpu_memory, PYTORCH_AVAILABLE
    )
    from autoencoder_visualization import (
        plot_training_history, visualize_latent_space, analyze_reconstruction_error,
        generate_comparison_analysis, compare_with_pod_results
    )
    from autoencoder_prediction import (
        create_autoencoder_prediction_pipeline, save_prediction_summary
    )


def perform_autoencoder_analysis(rcs_data, theta_values, phi_values, param_data, param_names,
                                 freq_label, output_dir, train_indices, test_indices=None,
                                 latent_dims=[5, 10, 15, 20], model_types=['standard', 'vae'],
                                 device='auto', available_models=None, skip_training=False):
    """
    æ‰§è¡ŒåŸºäºAutoencoderçš„RCSæ•°æ®é™ç»´åˆ†æ

    å‚æ•°:
    rcs_data: RCSæ•°æ®çŸ©é˜µ [n_samples, n_features]
    theta_values: thetaè§’åº¦å€¼
    phi_values: phiè§’åº¦å€¼
    param_data: è®¾è®¡å‚æ•°æ•°æ®
    param_names: å‚æ•°åç§°åˆ—è¡¨
    freq_label: é¢‘ç‡æ ‡ç­¾
    output_dir: è¾“å‡ºç›®å½•
    train_indices: è®­ç»ƒé›†ç´¢å¼•
    test_indices: æµ‹è¯•é›†ç´¢å¼•ï¼ˆå¯é€‰ï¼‰
    latent_dims: æ½œåœ¨ç©ºé—´ç»´åº¦åˆ—è¡¨
    model_types: æ¨¡å‹ç±»å‹åˆ—è¡¨
    device: è®¡ç®—è®¾å¤‡
    available_models: å¯ç”¨æ¨¡å‹ç´¢å¼•

    è¿”å›:
    results: åˆ†æç»“æœå­—å…¸
    """
    try:
        validate_data_integrity(rcs_data, param_data, available_models)
    except Exception as e:
        print(f"âŒ æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥: {e}")
        return {}

    if not PYTORCH_AVAILABLE:
        print("PyTorchä¸å¯ç”¨ï¼Œè·³è¿‡Autoencoderåˆ†æ")
        return {}

    # è·å–è®¾å¤‡é…ç½®
    if device == 'auto':
        device, device_info = get_device_info()
        print(f"ğŸ–¥ï¸  {device_info}")
    else:
        device = torch.device(device)
        print(f"ğŸ–¥ï¸  ä½¿ç”¨æŒ‡å®šè®¾å¤‡: {device}")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    ae_dir = os.path.join(output_dir, 'autoencoder')
    os.makedirs(ae_dir, exist_ok=True)

    # æ•°æ®é¢„å¤„ç†
    print("å‡†å¤‡Autoencoderè®­ç»ƒæ•°æ®...")

    # åˆ†å‰²è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
    rcs_train = rcs_data[train_indices]
    param_train = param_data[train_indices]

    if test_indices is not None and len(test_indices) > 0:
        rcs_test = rcs_data[test_indices]
        param_test = param_data[test_indices]
    else:
        rcs_test = None
        param_test = None

    # æ•°æ®æ ‡å‡†åŒ–
    scaler = StandardScaler()
    rcs_train_scaled = scaler.fit_transform(rcs_train)
    if rcs_test is not None:
        rcs_test_scaled = scaler.transform(rcs_test)

    # è½¬æ¢ä¸ºå¼ é‡
    print("ğŸ”„ ä¼˜åŒ–æ•°æ®åŠ è½½...")
    rcs_train_tensor = torch.from_numpy(rcs_train_scaled.astype(np.float32)).contiguous()
    if rcs_test is not None:
        rcs_test_tensor = torch.from_numpy(rcs_test_scaled.astype(np.float32)).contiguous()
    else:
        rcs_test_tensor = None

    # æ•°æ®é›†ä¿¡æ¯
    input_dim = rcs_train_scaled.shape[1]
    print(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
    print(f"  è®­ç»ƒé›†å½¢çŠ¶: {rcs_train_scaled.shape}")
    if rcs_test is not None:
        print(f"  æµ‹è¯•é›†å½¢çŠ¶: {rcs_test_scaled.shape}")

    # æ£€æŸ¥æ•°æ®é›†å¤§å°
    if len(rcs_train_scaled) == 0:
        print("âŒ è®­ç»ƒæ•°æ®é›†ä¸ºç©º")
        return {}

    # ä¼˜åŒ–æ‰¹æ¬¡å¤§å°
    optimal_batch_size = get_optimal_batch_size(input_dim, device)
    max_reasonable_batch_size = max(1, len(rcs_train_scaled) // 4)
    optimal_batch_size = min(optimal_batch_size, max_reasonable_batch_size)

    print(f"ğŸ“¦ ä½¿ç”¨æ‰¹æ¬¡å¤§å°: {optimal_batch_size}")

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader, val_loader = create_optimized_data_loaders(
        rcs_train_tensor, rcs_test_tensor, device, optimal_batch_size
    )

    if train_loader is None or val_loader is None:
        print("âŒ æ•°æ®åŠ è½½å™¨åˆ›å»ºå¤±è´¥")
        return {}

    results = {}

    print(f"è¾“å…¥ç»´åº¦: {input_dim}")
    print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(rcs_train_scaled)}")
    print(f"å°†è®­ç»ƒ/åŠ è½½ä»¥ä¸‹é…ç½®:")
    print(f"  æ½œåœ¨ç»´åº¦: {latent_dims}")
    print(f"  æ¨¡å‹ç±»å‹: {model_types}")
    print(f"  è·³è¿‡è®­ç»ƒ: {skip_training}")

    # å¦‚æœå¯ç”¨è·³è¿‡è®­ç»ƒï¼Œæ£€æŸ¥å·²æœ‰æ¨¡å‹
    existing_models = {}
    if skip_training:
        print("\nğŸ” æ£€æŸ¥å·²æœ‰æ¨¡å‹...")
        existing_models = check_existing_models(ae_dir, latent_dims, model_types)
        if existing_models:
            print(f"æ‰¾åˆ° {len(existing_models)} ä¸ªå®Œæ•´çš„å·²æœ‰æ¨¡å‹")
        else:
            print("æœªæ‰¾åˆ°å®Œæ•´çš„å·²æœ‰æ¨¡å‹ï¼Œå°†è¿›è¡Œè®­ç»ƒ")

    # è®­ç»ƒ/åŠ è½½ä¸åŒé…ç½®çš„æ¨¡å‹
    for model_type in model_types:
        for latent_dim in latent_dims:
            config_name = f"{model_type}_latent{latent_dim}"
            config_dir = os.path.join(ae_dir, config_name)
            os.makedirs(config_dir, exist_ok=True)
            
            # æ£€æŸ¥æ˜¯å¦å¯ä»¥è·³è¿‡è®­ç»ƒ
            if skip_training and config_name in existing_models:
                print(f"\nğŸ“¥ åŠ è½½å·²æœ‰æ¨¡å‹: {config_name}")
                
                model_data = load_existing_model(config_dir, device)
                if model_data:
                    # é‡æ–°è¯„ä¼°åŠ è½½çš„æ¨¡å‹ä»¥è·å¾—å®Œæ•´çš„ç»“æœ
                    print(f"  é‡æ–°è¯„ä¼°å·²åŠ è½½æ¨¡å‹çš„æ€§èƒ½...")
                    
                    try:
                        # å‡†å¤‡æ ‡å‡†åŒ–å™¨
                        eval_scaler = model_data['scaler']
                        if eval_scaler is None:
                            # å¦‚æœæ²¡æœ‰ä¿å­˜çš„æ ‡å‡†åŒ–å™¨ï¼Œä½¿ç”¨å½“å‰çš„æ ‡å‡†åŒ–å™¨
                            eval_scaler = scaler
                            print(f"    ä½¿ç”¨å½“å‰æ ‡å‡†åŒ–å™¨è¿›è¡Œè¯„ä¼°")
                        
                        # é‡æ–°è¯„ä¼°è®­ç»ƒé›†ï¼ˆä½¿ç”¨å½“å‰çš„æ•°æ®ï¼Œä¸ä¾èµ–ä¿å­˜çš„ç´¢å¼•ï¼‰
                        train_results = evaluate_model(model_data['model'], rcs_train_tensor, 
                                                     eval_scaler, device, model_data['model_type'])
                        
                        print(f"    è®­ç»ƒé›†é‡æ„MSE: {train_results['mse']:.6f}")
                        print(f"    è®­ç»ƒé›†é‡æ„RÂ²: {train_results['r2']:.6f}")
                        
                        # æ„é€ ç»“æœæ ¼å¼
                        config_results = {
                            'model_type': model_data['model_type'],
                            'latent_dim': model_data['latent_dim'],
                            'model': model_data['model'],
                            'train_losses': [],  # å·²æœ‰æ¨¡å‹æ— è®­ç»ƒå†å²
                            'val_losses': [],
                            'train_latent': train_results['latent'],
                            'train_recon': train_results['reconstruction'],
                            'scaler': eval_scaler,
                            'mse': train_results['mse'],
                            'r2': train_results['r2']
                        }
                        
                        # å¦‚æœæœ‰æµ‹è¯•é›†æ•°æ®
                        if rcs_test is not None and rcs_test_tensor is not None:
                            test_results = evaluate_model(model_data['model'], rcs_test_tensor,
                                                        eval_scaler, device, model_data['model_type'])
                            
                            print(f"    æµ‹è¯•é›†é‡æ„MSE: {test_results['mse']:.6f}")
                            print(f"    æµ‹è¯•é›†é‡æ„RÂ²: {test_results['r2']:.6f}")
                            
                            config_results.update({
                                'test_latent': test_results['latent'],
                                'test_recon': test_results['reconstruction'],
                                'test_mse': test_results['mse'],
                                'test_r2': test_results['r2']
                            })
                        
                        results[config_name] = config_results
                        
                        # é‡æ–°ç”Ÿæˆå¯è§†åŒ–ï¼ˆå› ä¸ºæˆ‘ä»¬æœ‰äº†æ–°çš„è¯„ä¼°ç»“æœï¼‰
                        visualize_latent_space(train_results['latent'], param_train, param_names,
                                             f"{config_name}_è®­ç»ƒé›†", config_dir)
                        
                        if rcs_test is not None and 'test_latent' in config_results:
                            visualize_latent_space(config_results['test_latent'], param_test, param_names,
                                                 f"{config_name}_æµ‹è¯•é›†", config_dir)
                        
                        print(f"  âœ… æˆåŠŸåŠ è½½å¹¶é‡æ–°è¯„ä¼°æ¨¡å‹ {config_name}")
                        continue
                        
                    except Exception as eval_error:
                        print(f"    âŒ é‡æ–°è¯„ä¼°æ¨¡å‹å¤±è´¥: {eval_error}")
                        print(f"    å°†é‡æ–°è®­ç»ƒæ¨¡å‹")
                        
                else:
                    print(f"  åŠ è½½å·²æœ‰æ¨¡å‹å¤±è´¥ï¼Œå°†é‡æ–°è®­ç»ƒ")
            
            print(f"\nğŸš€ å¼€å§‹è®­ç»ƒé…ç½®: {config_name}")

            # åˆ›å»ºæ¨¡å‹
            if model_type == 'standard':
                model = StandardAutoencoder(input_dim, latent_dim)
            else:  # VAE
                model = VariationalAutoencoder(input_dim, latent_dim)

            # è®­ç»ƒæ¨¡å‹
            try:
                trained_model, train_losses, val_losses = train_autoencoder(
                    model, train_loader, val_loader, epochs=200,
                    device=device, model_type=model_type, output_dir=config_dir
                )

                # æ£€æŸ¥è®­ç»ƒæ˜¯å¦æˆåŠŸå®Œæˆ
                if len(train_losses) == 0:
                    print(f"  âš ï¸ è­¦å‘Šï¼š{config_name} è®­ç»ƒå¤±è´¥ï¼Œæ²¡æœ‰è®°å½•è®­ç»ƒæŸå¤±")
                    continue
                
                # è¯„ä¼°è®­ç»ƒé›†
                train_results = evaluate_model(trained_model, rcs_train_tensor, scaler, device, model_type)
                
                print(f"  è®­ç»ƒé›†é‡æ„MSE: {train_results['mse']:.6f}")
                print(f"  è®­ç»ƒé›†é‡æ„R^2: {train_results['r2']:.6f}")
                print(f"  è®­ç»ƒè½®æ•°: {len(train_losses)}, æœ€ç»ˆè®­ç»ƒæŸå¤±: {train_losses[-1]:.6f}")

                # ä¿å­˜ç»“æœ
                config_results = {
                    'model_type': model_type,
                    'latent_dim': latent_dim,
                    'model': trained_model,
                    'train_losses': train_losses,
                    'val_losses': val_losses,
                    'train_latent': train_results['latent'],
                    'train_recon': train_results['reconstruction'],
                    'scaler': scaler,
                    'mse': train_results['mse'],
                    'r2': train_results['r2']
                }

                # å¦‚æœæœ‰æµ‹è¯•é›†ï¼Œä¹Ÿè¿›è¡Œè¯„ä¼°
                if rcs_test is not None:
                    test_results = evaluate_model(trained_model, rcs_test_tensor, scaler, device, model_type)
                    
                    print(f"  æµ‹è¯•é›†é‡æ„MSE: {test_results['mse']:.6f}")
                    print(f"  æµ‹è¯•é›†é‡æ„R^2: {test_results['r2']:.6f}")

                    config_results.update({
                        'test_latent': test_results['latent'],
                        'test_recon': test_results['reconstruction'],
                        'test_mse': test_results['mse'],
                        'test_r2': test_results['r2']
                    })

                results[config_name] = config_results

                # ç»˜åˆ¶è®­ç»ƒå†å²
                plot_training_history(train_losses, val_losses, config_name, config_dir)

                # ä¿å­˜å®Œæ•´çš„æ¨¡å‹å’Œæ•°æ®
                print(f"  ä¿å­˜æ¨¡å‹å’Œéšç©ºé—´æ•°æ®...")
                
                # ä¿å­˜å®Œæ•´çš„æ¨¡å‹æ–‡ä»¶ï¼ˆåŒ…å«ç»“æ„ä¿¡æ¯ï¼‰
                model_file = os.path.join(config_dir, 'autoencoder_model.pth')
                try:
                    model_to_save = trained_model.module if hasattr(trained_model, 'module') else trained_model
                    torch.save({
                        'model_state_dict': model_to_save.state_dict(),
                        'model_type': model_type,
                        'model_params': {
                            'input_dim': input_dim,
                            'latent_dim': latent_dim
                        },
                        'train_losses': train_losses,
                        'val_losses': val_losses,
                        'final_train_mse': train_results['mse'],
                        'final_train_r2': train_results['r2']
                    }, model_file)
                    print(f"    âœ… æ¨¡å‹å·²ä¿å­˜: autoencoder_model.pth")
                except Exception as e:
                    print(f"    âŒ æ¨¡å‹ä¿å­˜å¤±è´¥: {e}")
                
                # ä¿å­˜æ ‡å‡†åŒ–å™¨
                scaler_file = os.path.join(config_dir, 'scaler.pkl')
                try:
                    import pickle
                    with open(scaler_file, 'wb') as f:
                        pickle.dump(scaler, f)
                    print(f"    âœ… æ ‡å‡†åŒ–å™¨å·²ä¿å­˜: scaler.pkl")
                except Exception as e:
                    print(f"    âŒ æ ‡å‡†åŒ–å™¨ä¿å­˜å¤±è´¥: {e}")
                
                # ä¿å­˜è®­ç»ƒé›†éšç©ºé—´æ•°æ®
                train_latent_file = os.path.join(config_dir, 'train_latent_space.npy')
                np.save(train_latent_file, train_results['latent'])
                print(f"    âœ… è®­ç»ƒé›†éšç©ºé—´æ•°æ®å·²ä¿å­˜: train_latent_space.npy")
                
                # ä¿å­˜è®­ç»ƒé›†ç´¢å¼•
                train_indices_file = os.path.join(config_dir, 'train_indices.npy')
                np.save(train_indices_file, train_indices)
                print(f"    âœ… è®­ç»ƒé›†ç´¢å¼•å·²ä¿å­˜: train_indices.npy")
                
                # ä¿å­˜è®­ç»ƒé›†å‚æ•°æ•°æ®
                train_params_file = os.path.join(config_dir, 'train_parameters.npy')
                np.save(train_params_file, param_train)
                print(f"    âœ… è®­ç»ƒé›†å‚æ•°å·²ä¿å­˜: train_parameters.npy")
                
                if rcs_test is not None:
                    # ä¿å­˜æµ‹è¯•é›†éšç©ºé—´æ•°æ®
                    test_latent_file = os.path.join(config_dir, 'test_latent_space.npy')
                    np.save(test_latent_file, test_results['latent'])
                    print(f"    âœ… æµ‹è¯•é›†éšç©ºé—´æ•°æ®å·²ä¿å­˜: test_latent_space.npy")
                    
                    # ä¿å­˜æµ‹è¯•é›†ç´¢å¼•
                    test_indices_file = os.path.join(config_dir, 'test_indices.npy')
                    np.save(test_indices_file, test_indices)
                    print(f"    âœ… æµ‹è¯•é›†ç´¢å¼•å·²ä¿å­˜: test_indices.npy")
                    
                    # ä¿å­˜æµ‹è¯•é›†å‚æ•°æ•°æ®
                    test_params_file = os.path.join(config_dir, 'test_parameters.npy')
                    np.save(test_params_file, param_test)
                    print(f"    âœ… æµ‹è¯•é›†å‚æ•°å·²ä¿å­˜: test_parameters.npy")

                # å¯è§†åŒ–æ½œåœ¨ç©ºé—´
                visualize_latent_space(train_results['latent'], param_train, param_names,
                                       f"{config_name}_è®­ç»ƒé›†", config_dir)

                if rcs_test is not None:
                    visualize_latent_space(test_results['latent'], param_test, param_names,
                                           f"{config_name}_æµ‹è¯•é›†", config_dir)

                # é‡æ„è¯¯å·®åˆ†æ
                analyze_reconstruction_error(rcs_train, train_results['reconstruction'], 
                                             theta_values, phi_values,
                                             f"{config_name}_è®­ç»ƒé›†", config_dir)

                print(f"  é…ç½® {config_name} è®­ç»ƒå®Œæˆ")

            except Exception as e:
                print(f"  é…ç½® {config_name} è®­ç»ƒå¤±è´¥: {e}")
                import traceback
                traceback.print_exc()

    # ç”Ÿæˆå¯¹æ¯”åˆ†æ
    if results:
        generate_comparison_analysis(results, ae_dir)
        
        # åˆ›å»ºéšç©ºé—´æ•°æ®ç´¢å¼•æ–‡ä»¶
        create_latent_space_index(results, ae_dir, freq_label)
        
        # å¦‚æœæœ‰æµ‹è¯•é›†ï¼Œåˆ›å»ºé¢„æµ‹æ¨¡å‹
        if test_indices is not None and len(test_indices) > 0:
            print("\nğŸ”® åˆ›å»ºAutoencoderé¢„æµ‹æ¨¡å‹...")
            prediction_dir = os.path.join(ae_dir, 'predictions')
            
            try:
                prediction_results = create_autoencoder_prediction_pipeline(
                    results, param_data[train_indices], param_data[test_indices], prediction_dir
                )
                
                if prediction_results:
                    save_prediction_summary(prediction_results, prediction_dir)
                    print(f"âœ… Autoencoderé¢„æµ‹æ¨¡å‹åˆ›å»ºå®Œæˆ")
                else:
                    print("âš ï¸  æœªèƒ½åˆ›å»ºä»»ä½•é¢„æµ‹æ¨¡å‹")
                    
            except Exception as e:
                print(f"âŒ åˆ›å»ºé¢„æµ‹æ¨¡å‹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
        
        print(f"\nAutoencoderåˆ†æå®Œæˆï¼Œç»“æœä¿å­˜åœ¨: {ae_dir}")
    else:
        print("\nAutoencoderåˆ†æå¤±è´¥ï¼Œæ²¡æœ‰æˆåŠŸè®­ç»ƒçš„æ¨¡å‹")

    # æ¸…ç†GPUå†…å­˜
    cleanup_gpu_memory()

    return results


def check_existing_models(ae_dir, latent_dims, model_types):
    """
    æ£€æŸ¥å·²æœ‰çš„Autoencoderæ¨¡å‹
    
    å‚æ•°:
    ae_dir: autoencoderç›®å½•
    latent_dims: æ½œåœ¨ç©ºé—´ç»´åº¦åˆ—è¡¨
    model_types: æ¨¡å‹ç±»å‹åˆ—è¡¨
    
    è¿”å›:
    existing_models: å­—å…¸ï¼ŒåŒ…å«å·²æœ‰æ¨¡å‹çš„é…ç½®ä¿¡æ¯
    """
    existing_models = {}
    
    for model_type in model_types:
        for latent_dim in latent_dims:
            config_name = f"{model_type}_latent{latent_dim}"
            config_dir = os.path.join(ae_dir, config_name)
            model_file = os.path.join(config_dir, f'best_{model_type}_model.pth')
            
            if os.path.exists(model_file):
                # æ£€æŸ¥æ ¸å¿ƒæ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                core_files = [f'best_{model_type}_model.pth']
                optional_files = [
                    'scaler.pkl',
                    'train_latent_space.npy', 
                    'train_indices.npy',
                    'train_parameters.npy'
                ]
                
                core_files_exist = all(
                    os.path.exists(os.path.join(config_dir, fname)) 
                    for fname in core_files
                )
                
                optional_files_exist = all(
                    os.path.exists(os.path.join(config_dir, fname))
                    for fname in optional_files
                )
                
                if core_files_exist:
                    existing_models[config_name] = {
                        'config_dir': config_dir,
                        'model_type': model_type,
                        'latent_dim': latent_dim,
                        'complete': optional_files_exist,
                        'has_core': True
                    }
                    if optional_files_exist:
                        print(f"  æ‰¾åˆ°å®Œæ•´çš„å·²æœ‰æ¨¡å‹: {config_name}")
                    else:
                        print(f"  æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {config_name} (ç¼ºå°‘è¾…åŠ©æ–‡ä»¶ï¼Œå°†é‡æ–°è¯„ä¼°)")
                else:
                    print(f"  æ¨¡å‹ {config_name} æ ¸å¿ƒæ–‡ä»¶ç¼ºå¤±ï¼Œå°†é‡æ–°è®­ç»ƒ")
    
    return existing_models


def load_existing_model(config_dir, device):
    """
    åŠ è½½å·²æœ‰çš„Autoencoderæ¨¡å‹
    
    å‚æ•°:
    config_dir: é…ç½®ç›®å½•
    device: è®¡ç®—è®¾å¤‡
    
    è¿”å›:
    model_data: åŒ…å«æ¨¡å‹å’Œç›¸å…³æ•°æ®çš„å­—å…¸
    """
    import pickle
    
    try:
        # åŠ è½½æ¨¡å‹ç»“æ„ - å…ˆæ£€æŸ¥æ–°çš„æ–‡ä»¶åï¼Œå†æ£€æŸ¥æ—§çš„æ–‡ä»¶å
        model_file = os.path.join(config_dir, 'autoencoder_model.pth')
        if not os.path.exists(model_file):
            # æ£€æŸ¥æ—§çš„å‘½åè§„åˆ™
            for model_type in ['standard', 'vae']:
                old_model_file = os.path.join(config_dir, f'best_{model_type}_model.pth')
                if os.path.exists(old_model_file):
                    model_file = old_model_file
                    break
        model_state = torch.load(model_file, map_location=device)
        
        # ä»çŠ¶æ€å­—å…¸ä¸­é‡å»ºæ¨¡å‹
        if 'model_type' in model_state and 'model_params' in model_state:
            # æ–°æ ¼å¼æ¨¡å‹æ–‡ä»¶
            model_type = model_state['model_type']
            model_params = model_state['model_params']
        else:
            # æ—§æ ¼å¼æ¨¡å‹æ–‡ä»¶ï¼Œä»æ–‡ä»¶åæ¨æ–­
            if 'best_standard_model.pth' in model_file:
                model_type = 'standard'
            elif 'best_vae_model.pth' in model_file:
                model_type = 'vae'
            else:
                raise ValueError("æ— æ³•ä»æ–‡ä»¶åç¡®å®šæ¨¡å‹ç±»å‹")
            
            # ä»é…ç½®ç›®å½•åæ¨æ–­æ½œåœ¨ç»´åº¦
            config_name = os.path.basename(config_dir)
            if '_latent' in config_name:
                latent_dim = int(config_name.split('_latent')[1])
            else:
                raise ValueError("æ— æ³•ä»ç›®å½•åç¡®å®šæ½œåœ¨ç»´åº¦")
            
            # å‡è®¾è¾“å…¥ç»´åº¦ï¼ˆRCSæ•°æ®ç»´åº¦ï¼‰
            input_dim = 8281  # 91x91è§’åº¦ç»„åˆ
            
            model_params = {
                'input_dim': input_dim,
                'latent_dim': latent_dim
            }
            
            print(f"    ä»æ–‡ä»¶åæ¨æ–­: {model_type}, æ½œåœ¨ç»´åº¦: {latent_dim}")
        
        # åˆ›å»ºæ¨¡å‹
        if model_type == 'standard':
            from autoencoder_models import StandardAutoencoder
            model = StandardAutoencoder(model_params['input_dim'], model_params['latent_dim'])
        else:  # VAE
            from autoencoder_models import VariationalAutoencoder  
            model = VariationalAutoencoder(model_params['input_dim'], model_params['latent_dim'])
        
        model.load_state_dict(model_state['model_state_dict'])
        model.to(device)
        model.eval()
        
        # å°è¯•åŠ è½½æ ‡å‡†åŒ–å™¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        scaler_file = os.path.join(config_dir, 'scaler.pkl')
        scaler = None
        if os.path.exists(scaler_file):
            try:
                with open(scaler_file, 'rb') as f:
                    scaler = pickle.load(f)
                print(f"    âœ… åŠ è½½å·²æœ‰æ ‡å‡†åŒ–å™¨")
            except Exception as e:
                print(f"    âš ï¸ æ ‡å‡†åŒ–å™¨åŠ è½½å¤±è´¥: {e}")
        else:
            print(f"    âš ï¸ æ ‡å‡†åŒ–å™¨æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨é»˜è®¤æ ‡å‡†åŒ–å™¨")
        
        # å°è¯•åŠ è½½éšç©ºé—´æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        train_latent = None
        train_indices = None  
        train_params = None
        test_latent = None
        test_indices = None
        test_params = None
        
        train_latent_file = os.path.join(config_dir, 'train_latent_space.npy')
        if os.path.exists(train_latent_file):
            try:
                train_latent = np.load(train_latent_file)
                train_indices = np.load(os.path.join(config_dir, 'train_indices.npy'))
                train_params = np.load(os.path.join(config_dir, 'train_parameters.npy'))
                print(f"    âœ… åŠ è½½å·²æœ‰éšç©ºé—´æ•°æ®")
            except Exception as e:
                print(f"    âš ï¸ éšç©ºé—´æ•°æ®åŠ è½½å¤±è´¥: {e}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•é›†æ•°æ®
        test_latent_file = os.path.join(config_dir, 'test_latent_space.npy')
        if os.path.exists(test_latent_file):
            try:
                test_latent = np.load(test_latent_file)
                test_indices = np.load(os.path.join(config_dir, 'test_indices.npy'))
                test_params = np.load(os.path.join(config_dir, 'test_parameters.npy'))
                print(f"    âœ… åŠ è½½å·²æœ‰æµ‹è¯•é›†æ•°æ®")
            except Exception as e:
                print(f"    âš ï¸ æµ‹è¯•é›†æ•°æ®åŠ è½½å¤±è´¥: {e}")
        
        model_data = {
            'model': model,
            'scaler': scaler,
            'train_latent': train_latent,
            'train_indices': train_indices,
            'train_params': train_params,
            'test_latent': test_latent,
            'test_indices': test_indices,
            'test_params': test_params,
            'model_type': model_type,
            'latent_dim': model_params['latent_dim']
        }
        
        return model_data
        
    except Exception as e:
        print(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        return None


def create_latent_space_index(results, ae_dir, freq_label):
    """
    åˆ›å»ºéšç©ºé—´æ•°æ®ç´¢å¼•æ–‡ä»¶
    
    å‚æ•°:
    results: åˆ†æç»“æœå­—å…¸
    ae_dir: autoencoderç›®å½•
    freq_label: é¢‘ç‡æ ‡ç­¾
    """
    import json
    from datetime import datetime
    
    index_data = {
        'created_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'frequency': freq_label,
        'models': []
    }
    
    for config_name, config_results in results.items():
        model_info = {
            'config_name': config_name,
            'model_type': config_results['model_type'],
            'latent_dim': config_results['latent_dim'],
            'train_mse': float(config_results['mse']),
            'train_r2': float(config_results['r2']),
            'files': {
                'train_latent_space': f"{config_name}/train_latent_space.npy",
                'train_indices': f"{config_name}/train_indices.npy", 
                'train_parameters': f"{config_name}/train_parameters.npy"
            }
        }
        
        # å¦‚æœæœ‰æµ‹è¯•é›†æ•°æ®
        if 'test_mse' in config_results:
            model_info['test_mse'] = float(config_results['test_mse'])
            model_info['test_r2'] = float(config_results['test_r2'])
            model_info['files'].update({
                'test_latent_space': f"{config_name}/test_latent_space.npy",
                'test_indices': f"{config_name}/test_indices.npy",
                'test_parameters': f"{config_name}/test_parameters.npy"
            })
        
        index_data['models'].append(model_info)
    
    # ä¿å­˜ç´¢å¼•æ–‡ä»¶
    index_file = os.path.join(ae_dir, 'latent_space_index.json')
    with open(index_file, 'w', encoding='utf-8') as f:
        json.dump(index_data, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“‹ éšç©ºé—´æ•°æ®ç´¢å¼•å·²ä¿å­˜: {index_file}")
    print(f"   åŒ…å« {len(results)} ä¸ªæ¨¡å‹é…ç½®çš„éšç©ºé—´æ•°æ®")


# åœ¨ç°æœ‰çš„importéƒ¨åˆ†æ£€æŸ¥å¹¶è®°å½•PyTorchå¯ç”¨æ€§
if __name__ == "__main__":
    print("Autoencoderåˆ†ææ¨¡å—æµ‹è¯•")
    if PYTORCH_AVAILABLE:
        print("âœ“ PyTorchå·²å®‰è£…ï¼Œæ‰€æœ‰åŠŸèƒ½å¯ç”¨")

        # æµ‹è¯•æ¨¡å‹åˆ›å»º
        test_model_std = StandardAutoencoder(8281, 10)
        test_model_vae = VariationalAutoencoder(8281, 10)

        print(f"âœ“ æ ‡å‡†è‡ªç¼–ç å™¨å‚æ•°æ•°é‡: {sum(p.numel() for p in test_model_std.parameters()):,}")
        print(f"âœ“ å˜åˆ†è‡ªç¼–ç å™¨å‚æ•°æ•°é‡: {sum(p.numel() for p in test_model_vae.parameters()):,}")
    else:
        print("âœ— PyTorchæœªå®‰è£…ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…:")
        print("pip install torch torchvision torchaudio")