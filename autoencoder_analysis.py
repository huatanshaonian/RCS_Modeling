"""
åŸºäºæ·±åº¦å­¦ä¹ Autoencoderçš„RCSæ•°æ®é™ç»´åˆ†ææ¨¡å—
ä½¿ç”¨PyTorchå®ç°å˜åˆ†è‡ªç¼–ç å™¨(VAE)å’Œæ ‡å‡†è‡ªç¼–ç å™¨(AE)ç”¨äºRCSæ•°æ®é™ç»´

é‡æ„åçš„ä¸»åˆ†ææ¨¡å—ï¼Œåè°ƒå„ä¸ªå­æ¨¡å—çš„åŠŸèƒ½
"""

import os
import numpy as np
from sklearn.preprocessing import StandardScaler
import torch
from torch.utils.data import TensorDataset
import warnings

warnings.filterwarnings('ignore')

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
try:
    from .autoencoder_models import StandardAutoencoder, VariationalAutoencoder
    from .autoencoder_training import train_autoencoder, evaluate_model
    from .autoencoder_utils import (
        validate_data_integrity, get_device_info, get_optimal_batch_size,
        create_optimized_data_loaders, log_info, cleanup_gpu_memory, PYTORCH_AVAILABLE
    )
    from .autoencoder_visualization import (
        plot_training_history, visualize_latent_space, analyze_reconstruction_error,
        generate_comparison_analysis, compare_with_pod_results
    )
except ImportError:
    # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ç»å¯¹å¯¼å…¥
    from autoencoder_models import StandardAutoencoder, VariationalAutoencoder
    from autoencoder_training import train_autoencoder, evaluate_model
    from autoencoder_utils import (
        validate_data_integrity, get_device_info, get_optimal_batch_size,
        create_optimized_data_loaders, log_info, cleanup_gpu_memory, PYTORCH_AVAILABLE
    )
    from autoencoder_visualization import (
        plot_training_history, visualize_latent_space, analyze_reconstruction_error,
        generate_comparison_analysis, compare_with_pod_results
    )


def perform_autoencoder_analysis(rcs_data, theta_values, phi_values, param_data, param_names,
                                 freq_label, output_dir, train_indices, test_indices=None,
                                 latent_dims=[5, 10, 15, 20], model_types=['standard', 'vae'],
                                 device='auto', available_models=None):
    """
    æ‰§è¡ŒåŸºäºAutoencoderçš„RCSæ•°æ®é™ç»´åˆ†æ

    å‚æ•°:
    rcs_data: RCSæ•°æ®çŸ©é˜µ [n_samples, n_features]
    theta_values: thetaè§’åº¦å€¼
    phi_values: phiè§’åº¦å€¼
    param_data: è®¾è®¡å‚æ•°æ•°æ®
    param_names: å‚æ•°åç§°åˆ—è¡¨
    freq_label: é¢‘ç‡æ ‡ç­¾
    output_dir: è¾“å‡ºç›®å½•
    train_indices: è®­ç»ƒé›†ç´¢å¼•
    test_indices: æµ‹è¯•é›†ç´¢å¼•ï¼ˆå¯é€‰ï¼‰
    latent_dims: æ½œåœ¨ç©ºé—´ç»´åº¦åˆ—è¡¨
    model_types: æ¨¡å‹ç±»å‹åˆ—è¡¨
    device: è®¡ç®—è®¾å¤‡
    available_models: å¯ç”¨æ¨¡å‹ç´¢å¼•

    è¿”å›:
    results: åˆ†æç»“æœå­—å…¸
    """
    try:
        validate_data_integrity(rcs_data, param_data, available_models)
    except Exception as e:
        print(f"âŒ æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥: {e}")
        return {}

    if not PYTORCH_AVAILABLE:
        print("PyTorchä¸å¯ç”¨ï¼Œè·³è¿‡Autoencoderåˆ†æ")
        return {}

    # è·å–è®¾å¤‡é…ç½®
    if device == 'auto':
        device, device_info = get_device_info()
        print(f"ğŸ–¥ï¸  {device_info}")
    else:
        device = torch.device(device)
        print(f"ğŸ–¥ï¸  ä½¿ç”¨æŒ‡å®šè®¾å¤‡: {device}")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    ae_dir = os.path.join(output_dir, 'autoencoder')
    os.makedirs(ae_dir, exist_ok=True)

    # æ•°æ®é¢„å¤„ç†
    print("å‡†å¤‡Autoencoderè®­ç»ƒæ•°æ®...")

    # åˆ†å‰²è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
    rcs_train = rcs_data[train_indices]
    param_train = param_data[train_indices]

    if test_indices is not None and len(test_indices) > 0:
        rcs_test = rcs_data[test_indices]
        param_test = param_data[test_indices]
    else:
        rcs_test = None
        param_test = None

    # æ•°æ®æ ‡å‡†åŒ–
    scaler = StandardScaler()
    rcs_train_scaled = scaler.fit_transform(rcs_train)
    if rcs_test is not None:
        rcs_test_scaled = scaler.transform(rcs_test)

    # è½¬æ¢ä¸ºå¼ é‡
    print("ğŸ”„ ä¼˜åŒ–æ•°æ®åŠ è½½...")
    rcs_train_tensor = torch.from_numpy(rcs_train_scaled.astype(np.float32)).contiguous()
    if rcs_test is not None:
        rcs_test_tensor = torch.from_numpy(rcs_test_scaled.astype(np.float32)).contiguous()
    else:
        rcs_test_tensor = None

    # æ•°æ®é›†ä¿¡æ¯
    input_dim = rcs_train_scaled.shape[1]
    print(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
    print(f"  è®­ç»ƒé›†å½¢çŠ¶: {rcs_train_scaled.shape}")
    if rcs_test is not None:
        print(f"  æµ‹è¯•é›†å½¢çŠ¶: {rcs_test_scaled.shape}")

    # æ£€æŸ¥æ•°æ®é›†å¤§å°
    if len(rcs_train_scaled) == 0:
        print("âŒ è®­ç»ƒæ•°æ®é›†ä¸ºç©º")
        return {}

    # ä¼˜åŒ–æ‰¹æ¬¡å¤§å°
    optimal_batch_size = get_optimal_batch_size(input_dim, device)
    max_reasonable_batch_size = max(1, len(rcs_train_scaled) // 4)
    optimal_batch_size = min(optimal_batch_size, max_reasonable_batch_size)

    print(f"ğŸ“¦ ä½¿ç”¨æ‰¹æ¬¡å¤§å°: {optimal_batch_size}")

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader, val_loader = create_optimized_data_loaders(
        rcs_train_tensor, rcs_test_tensor, device, optimal_batch_size
    )

    if train_loader is None or val_loader is None:
        print("âŒ æ•°æ®åŠ è½½å™¨åˆ›å»ºå¤±è´¥")
        return {}

    results = {}

    print(f"è¾“å…¥ç»´åº¦: {input_dim}")
    print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(rcs_train_scaled)}")
    print(f"å°†è®­ç»ƒä»¥ä¸‹é…ç½®:")
    print(f"  æ½œåœ¨ç»´åº¦: {latent_dims}")
    print(f"  æ¨¡å‹ç±»å‹: {model_types}")

    # è®­ç»ƒä¸åŒé…ç½®çš„æ¨¡å‹
    for model_type in model_types:
        for latent_dim in latent_dims:
            config_name = f"{model_type}_latent{latent_dim}"
            print(f"\nå¼€å§‹è®­ç»ƒé…ç½®: {config_name}")

            config_dir = os.path.join(ae_dir, config_name)
            os.makedirs(config_dir, exist_ok=True)

            # åˆ›å»ºæ¨¡å‹
            if model_type == 'standard':
                model = StandardAutoencoder(input_dim, latent_dim)
            else:  # VAE
                model = VariationalAutoencoder(input_dim, latent_dim)

            # è®­ç»ƒæ¨¡å‹
            try:
                trained_model, train_losses, val_losses = train_autoencoder(
                    model, train_loader, val_loader, epochs=200,
                    device=device, model_type=model_type, output_dir=config_dir
                )

                # æ£€æŸ¥è®­ç»ƒæ˜¯å¦æˆåŠŸå®Œæˆ
                if len(train_losses) == 0:
                    print(f"  âš ï¸ è­¦å‘Šï¼š{config_name} è®­ç»ƒå¤±è´¥ï¼Œæ²¡æœ‰è®°å½•è®­ç»ƒæŸå¤±")
                    continue
                
                # è¯„ä¼°è®­ç»ƒé›†
                train_results = evaluate_model(trained_model, rcs_train_tensor, scaler, device, model_type)
                
                print(f"  è®­ç»ƒé›†é‡æ„MSE: {train_results['mse']:.6f}")
                print(f"  è®­ç»ƒé›†é‡æ„R^2: {train_results['r2']:.6f}")
                print(f"  è®­ç»ƒè½®æ•°: {len(train_losses)}, æœ€ç»ˆè®­ç»ƒæŸå¤±: {train_losses[-1]:.6f}")

                # ä¿å­˜ç»“æœ
                config_results = {
                    'model_type': model_type,
                    'latent_dim': latent_dim,
                    'model': trained_model,
                    'train_losses': train_losses,
                    'val_losses': val_losses,
                    'train_latent': train_results['latent'],
                    'train_recon': train_results['reconstruction'],
                    'scaler': scaler,
                    'mse': train_results['mse'],
                    'r2': train_results['r2']
                }

                # å¦‚æœæœ‰æµ‹è¯•é›†ï¼Œä¹Ÿè¿›è¡Œè¯„ä¼°
                if rcs_test is not None:
                    test_results = evaluate_model(trained_model, rcs_test_tensor, scaler, device, model_type)
                    
                    print(f"  æµ‹è¯•é›†é‡æ„MSE: {test_results['mse']:.6f}")
                    print(f"  æµ‹è¯•é›†é‡æ„R^2: {test_results['r2']:.6f}")

                    config_results.update({
                        'test_latent': test_results['latent'],
                        'test_recon': test_results['reconstruction'],
                        'test_mse': test_results['mse'],
                        'test_r2': test_results['r2']
                    })

                results[config_name] = config_results

                # ç»˜åˆ¶è®­ç»ƒå†å²
                plot_training_history(train_losses, val_losses, config_name, config_dir)

                # å¯è§†åŒ–æ½œåœ¨ç©ºé—´
                visualize_latent_space(train_results['latent'], param_train, param_names,
                                       f"{config_name}_è®­ç»ƒé›†", config_dir)

                if rcs_test is not None:
                    visualize_latent_space(test_results['latent'], param_test, param_names,
                                           f"{config_name}_æµ‹è¯•é›†", config_dir)

                # é‡æ„è¯¯å·®åˆ†æ
                analyze_reconstruction_error(rcs_train, train_results['reconstruction'], 
                                             theta_values, phi_values,
                                             f"{config_name}_è®­ç»ƒé›†", config_dir)

                print(f"  é…ç½® {config_name} è®­ç»ƒå®Œæˆ")

            except Exception as e:
                print(f"  é…ç½® {config_name} è®­ç»ƒå¤±è´¥: {e}")
                import traceback
                traceback.print_exc()

    # ç”Ÿæˆå¯¹æ¯”åˆ†æ
    if results:
        generate_comparison_analysis(results, ae_dir)
        print(f"\nAutoencoderåˆ†æå®Œæˆï¼Œç»“æœä¿å­˜åœ¨: {ae_dir}")
    else:
        print("\nAutoencoderåˆ†æå¤±è´¥ï¼Œæ²¡æœ‰æˆåŠŸè®­ç»ƒçš„æ¨¡å‹")

    # æ¸…ç†GPUå†…å­˜
    cleanup_gpu_memory()

    return results


# åœ¨ç°æœ‰çš„importéƒ¨åˆ†æ£€æŸ¥å¹¶è®°å½•PyTorchå¯ç”¨æ€§
if __name__ == "__main__":
    print("Autoencoderåˆ†ææ¨¡å—æµ‹è¯•")
    if PYTORCH_AVAILABLE:
        print("âœ“ PyTorchå·²å®‰è£…ï¼Œæ‰€æœ‰åŠŸèƒ½å¯ç”¨")

        # æµ‹è¯•æ¨¡å‹åˆ›å»º
        test_model_std = StandardAutoencoder(8281, 10)
        test_model_vae = VariationalAutoencoder(8281, 10)

        print(f"âœ“ æ ‡å‡†è‡ªç¼–ç å™¨å‚æ•°æ•°é‡: {sum(p.numel() for p in test_model_std.parameters()):,}")
        print(f"âœ“ å˜åˆ†è‡ªç¼–ç å™¨å‚æ•°æ•°é‡: {sum(p.numel() for p in test_model_vae.parameters()):,}")
    else:
        print("âœ— PyTorchæœªå®‰è£…ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…:")
        print("pip install torch torchvision torchaudio")