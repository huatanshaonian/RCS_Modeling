"""
Autoencoderè®­ç»ƒæ¨¡å—
åŒ…å«è®­ç»ƒé€»è¾‘ã€ä¼˜åŒ–å™¨é…ç½®å’Œæ¨¡å‹è¯„ä¼°åŠŸèƒ½
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import numpy as np
from sklearn.metrics import mean_squared_error, r2_score

try:
    from .autoencoder_models import vae_loss_function
    from .autoencoder_utils import (
        log_info, log_progress, optimize_model_for_gpu, 
        monitor_gpu_memory, PYTORCH_AVAILABLE
    )
except ImportError:
    # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ç»å¯¹å¯¼å…¥
    from autoencoder_models import vae_loss_function
    from autoencoder_utils import (
        log_info, log_progress, optimize_model_for_gpu, 
        monitor_gpu_memory, PYTORCH_AVAILABLE
    )


def train_autoencoder(model, train_loader, val_loader, epochs=200, learning_rate=1e-3,
                      device='cpu', model_type='standard', beta=1.0, output_dir=None):
    """è®­ç»ƒè‡ªç¼–ç å™¨æ¨¡å‹ - ä¿®å¤StopIterationé”™è¯¯"""

    if not PYTORCH_AVAILABLE:
        raise ImportError("PyTorchä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œè®­ç»ƒ")

    # GPUä¼˜åŒ–æ¨¡å‹
    model = optimize_model_for_gpu(model, device)

    # ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆå¦‚æœæ”¯æŒï¼‰
    use_amp = device.type == 'cuda' and hasattr(torch.cuda, 'amp')
    if use_amp:
        log_info("å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ", "SUCCESS")
        scaler = torch.cuda.amp.GradScaler()

    # ä¼˜åŒ–å™¨è®¾ç½®
    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=20, factor=0.5)

    # è®­ç»ƒçŠ¶æ€å˜é‡
    train_losses = []
    val_losses = []
    best_val_loss = float('inf')
    patience_counter = 0
    patience = 50

    log_info(f"å¼€å§‹è®­ç»ƒ{model_type.upper()}æ¨¡å‹ (è®¾å¤‡: {device})")

    # ===== ä¿®å¤ï¼šå®‰å…¨çš„æ•°æ®è®¿é—®å’Œæ‰¹æ¬¡å¤§å°æµ‹è¯• =====
    try:
        # æ£€æŸ¥æ•°æ®åŠ è½½å™¨æ˜¯å¦ä¸ºç©º
        if len(train_loader) == 0:
            raise ValueError("è®­ç»ƒæ•°æ®åŠ è½½å™¨ä¸ºç©º")

        if len(val_loader) == 0:
            raise ValueError("éªŒè¯æ•°æ®åŠ è½½å™¨ä¸ºç©º")

        print(f"ğŸ“Š æ•°æ®åŠ è½½å™¨çŠ¶æ€:")
        print(f"  è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}")
        print(f"  éªŒè¯æ‰¹æ¬¡æ•°: {len(val_loader)}")
        print(f"  è®­ç»ƒæ ·æœ¬æ•°: {len(train_loader.dataset)}")
        print(f"  éªŒè¯æ ·æœ¬æ•°: {len(val_loader.dataset)}")

        # å®‰å…¨è·å–è¾“å…¥ç»´åº¦
        sample_batch = None
        for batch_data in train_loader:
            sample_batch = batch_data[0]
            break  # åªå–ç¬¬ä¸€æ‰¹æ•°æ®

        if sample_batch is None:
            raise ValueError("æ— æ³•ä»è®­ç»ƒæ•°æ®åŠ è½½å™¨è·å–æ ·æœ¬æ•°æ®")

        input_dim = sample_batch.shape[1]
        current_batch_size = sample_batch.shape[0]

        print(f"ğŸ“ æ•°æ®ç»´åº¦ä¿¡æ¯:")
        print(f"  è¾“å…¥ç»´åº¦: {input_dim}")
        print(f"  å½“å‰æ‰¹æ¬¡å¤§å°: {current_batch_size}")

        # GPUæ‰¹æ¬¡å¤§å°ä¼˜åŒ–ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        if device.type == 'cuda' and current_batch_size < 128:
            try:
                print("ğŸ” æµ‹è¯•æ›´å¤§æ‰¹æ¬¡å¤§å°çš„å¯è¡Œæ€§...")

                # æµ‹è¯•2å€æ‰¹æ¬¡å¤§å°
                test_batch_size = min(current_batch_size * 2, 128)
                test_data = torch.randn(test_batch_size, input_dim).to(device)

                with torch.cuda.amp.autocast() if use_amp else torch.no_grad():
                    if model_type == 'standard':
                        recon, _ = model(test_data)
                        loss = F.mse_loss(recon, test_data)
                    else:
                        recon, mu, logvar, _ = model(test_data)
                        loss, _, _ = vae_loss_function(recon, test_data, mu, logvar, 1.0)

                # æµ‹è¯•åå‘ä¼ æ’­
                loss.backward()
                optimizer.zero_grad()

                print(f"âœ… æ›´å¤§æ‰¹æ¬¡ {test_batch_size} æµ‹è¯•æˆåŠŸ")

                # æ¸…ç†æµ‹è¯•æ•°æ®
                del test_data, loss, recon
                if 'mu' in locals():
                    del mu, logvar
                torch.cuda.empty_cache()

            except RuntimeError as e:
                if "out of memory" in str(e):
                    print(f"âš ï¸  æ›´å¤§æ‰¹æ¬¡å¤§å°æ˜¾å­˜ä¸è¶³ï¼Œç»§ç»­ä½¿ç”¨å½“å‰å¤§å°")
                    torch.cuda.empty_cache()
                else:
                    print(f"âš ï¸  æ‰¹æ¬¡æµ‹è¯•å‡ºé”™: {e}")

        # GPUé¢„çƒ­ - ä¿®å¤ç‰ˆæœ¬ï¼ˆè§£å†³BatchNormæ‰¹æ¬¡å¤§å°é—®é¢˜ï¼‰
        if device.type == 'cuda':
            log_info("GPUé¢„çƒ­ä¸­...", "PROGRESS")
            try:
                # ä½¿ç”¨è‡³å°‘2ä¸ªæ ·æœ¬çš„æ‰¹æ¬¡å¤§å°é¿å…BatchNormé”™è¯¯
                batch_size_for_warmup = max(2, min(current_batch_size, 8))
                dummy_input = torch.randn(batch_size_for_warmup, input_dim).to(device)

                with torch.no_grad():
                    if model_type == 'standard':
                        _, _ = model(dummy_input)
                    else:
                        _, _, _, _ = model(dummy_input)

                torch.cuda.synchronize()
                del dummy_input
                torch.cuda.empty_cache()
                log_info("GPUé¢„çƒ­å®Œæˆ", "SUCCESS")

            except Exception as e:
                print(f"âš ï¸  GPUé¢„çƒ­å¤±è´¥: {e}")

    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å™¨æ£€æŸ¥å¤±è´¥: {e}")
        print("ä½¿ç”¨åŸºç¡€è®­ç»ƒæ¨¡å¼...")

    # ===== ä¸»è®­ç»ƒå¾ªç¯ =====
    try:
        for epoch in range(epochs):
            # è®­ç»ƒé˜¶æ®µ
            model.train()
            train_loss = 0.0
            train_recon_loss = 0.0
            train_kl_loss = 0.0
            train_batches = 0

            for batch_idx, batch_data in enumerate(train_loader):
                try:
                    batch_data = batch_data[0].to(device, non_blocking=True)
                    optimizer.zero_grad(set_to_none=True)

                    if use_amp:
                        # æ··åˆç²¾åº¦è®­ç»ƒ
                        with torch.cuda.amp.autocast():
                            if model_type == 'standard':
                                recon_batch, _ = model(batch_data)
                                loss = F.mse_loss(recon_batch, batch_data)
                            else:  # VAE
                                recon_batch, mu, logvar, _ = model(batch_data)
                                loss, recon_loss, kl_loss = vae_loss_function(recon_batch, batch_data, mu, logvar, beta)
                                train_recon_loss += recon_loss.item()
                                train_kl_loss += kl_loss.item()

                        scaler.scale(loss).backward()
                        scaler.unscale_(optimizer)
                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                        scaler.step(optimizer)
                        scaler.update()
                    else:
                        # æ ‡å‡†è®­ç»ƒ
                        if model_type == 'standard':
                            recon_batch, _ = model(batch_data)
                            loss = F.mse_loss(recon_batch, batch_data)
                        else:  # VAE
                            recon_batch, mu, logvar, _ = model(batch_data)
                            loss, recon_loss, kl_loss = vae_loss_function(recon_batch, batch_data, mu, logvar, beta)
                            train_recon_loss += recon_loss.item()
                            train_kl_loss += kl_loss.item()

                        loss.backward()
                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                        optimizer.step()

                    train_loss += loss.item()
                    train_batches += 1

                    # å®šæœŸç›‘æ§ï¼ˆé™ä½é¢‘ç‡å¹¶æ™ºèƒ½è¾“å‡ºï¼‰
                    if batch_idx % 100 == 0 and device.type == 'cuda':
                        # æ¯ä¸ªepochçš„å¼€å§‹å¼ºåˆ¶è¾“å‡ºï¼Œå…¶ä»–æ—¶å€™åªåœ¨å˜åŒ–æ—¶è¾“å‡º
                        force_output = (batch_idx == 0)
                        monitor_gpu_memory(force_output=force_output)

                except Exception as batch_error:
                    print(f"âš ï¸  æ‰¹æ¬¡ {batch_idx} å¤„ç†å¤±è´¥: {batch_error}")
                    continue  # è·³è¿‡æœ‰é—®é¢˜çš„æ‰¹æ¬¡

            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„è®­ç»ƒæ‰¹æ¬¡
            if train_batches == 0:
                print("âŒ æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•è®­ç»ƒæ‰¹æ¬¡")
                break

            # éªŒè¯é˜¶æ®µ
            model.eval()
            val_loss = 0.0
            val_recon_loss = 0.0
            val_kl_loss = 0.0
            val_batches = 0

            with torch.no_grad():
                for batch_data in val_loader:
                    try:
                        batch_data = batch_data[0].to(device, non_blocking=True)

                        if use_amp:
                            with torch.cuda.amp.autocast():
                                if model_type == 'standard':
                                    recon_batch, _ = model(batch_data)
                                    loss = F.mse_loss(recon_batch, batch_data)
                                else:  # VAE
                                    recon_batch, mu, logvar, _ = model(batch_data)
                                    loss, recon_loss, kl_loss = vae_loss_function(recon_batch, batch_data, mu, logvar,
                                                                                  beta)
                                    val_recon_loss += recon_loss.item()
                                    val_kl_loss += kl_loss.item()
                        else:
                            if model_type == 'standard':
                                recon_batch, _ = model(batch_data)
                                loss = F.mse_loss(recon_batch, batch_data)
                            else:  # VAE
                                recon_batch, mu, logvar, _ = model(batch_data)
                                loss, recon_loss, kl_loss = vae_loss_function(recon_batch, batch_data, mu, logvar, beta)
                                val_recon_loss += recon_loss.item()
                                val_kl_loss += kl_loss.item()

                        val_loss += loss.item()
                        val_batches += 1

                    except Exception as batch_error:
                        print(f"âš ï¸  éªŒè¯æ‰¹æ¬¡å¤„ç†å¤±è´¥: {batch_error}")
                        continue

            # æ£€æŸ¥éªŒè¯æ‰¹æ¬¡
            if val_batches == 0:
                print("âŒ æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•éªŒè¯æ‰¹æ¬¡")
                break

            # è®¡ç®—å¹³å‡æŸå¤± - ä¿®å¤é™¤é›¶é”™è¯¯
            avg_train_loss = train_loss / max(train_batches, 1)
            avg_val_loss = val_loss / max(val_batches, 1)

            train_losses.append(avg_train_loss)
            val_losses.append(avg_val_loss)

            # å­¦ä¹ ç‡è°ƒåº¦
            scheduler.step(avg_val_loss)

            # æ—©åœæ£€æŸ¥å’Œæ¨¡å‹ä¿å­˜
            if avg_val_loss < best_val_loss:
                best_val_loss = avg_val_loss
                patience_counter = 0
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                if output_dir:
                    try:
                        model_to_save = model.module if hasattr(model, 'module') else model
                        torch.save({
                            'model_state_dict': model_to_save.state_dict(),
                            'optimizer_state_dict': optimizer.state_dict(),
                            'epoch': epoch,
                            'loss': best_val_loss,
                        }, os.path.join(output_dir, f'best_{model_type}_model.pth'))
                    except Exception as save_error:
                        print(f"âš ï¸  æ¨¡å‹ä¿å­˜å¤±è´¥: {save_error}")
            else:
                patience_counter += 1

            # è¿›åº¦è¾“å‡º
            if epoch % 20 == 0 or epoch == epochs - 1:
                lr = optimizer.param_groups[0]['lr']
                if model_type == 'standard':
                    log_progress(epoch + 1, epochs,
                                 f"è®­ç»ƒæŸå¤±={avg_train_loss:.6f}, éªŒè¯æŸå¤±={avg_val_loss:.6f}, LR={lr:.2e}")
                else:
                    log_progress(epoch + 1, epochs, f"è®­ç»ƒæŸå¤±={avg_train_loss:.6f}, éªŒè¯æŸå¤±={avg_val_loss:.6f}")
                    if train_batches > 0:
                        log_info(
                            f"  é‡æ„æŸå¤±={train_recon_loss / train_batches:.6f}, KLæŸå¤±={train_kl_loss / train_batches:.6f}")

            # æ—©åœ
            if patience_counter >= patience:
                log_info(f"æ—©åœäºç¬¬ {epoch + 1} è½®ï¼Œæœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}", "WARNING")
                break

    except Exception as training_error:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {training_error}")
        import traceback
        traceback.print_exc()
        return model, train_losses, val_losses

    # åŠ è½½æœ€ä½³æ¨¡å‹
    if output_dir and os.path.exists(os.path.join(output_dir, f'best_{model_type}_model.pth')):
        try:
            checkpoint = torch.load(os.path.join(output_dir, f'best_{model_type}_model.pth'))
            if hasattr(model, 'module'):
                model.module.load_state_dict(checkpoint['model_state_dict'])
            else:
                model.load_state_dict(checkpoint['model_state_dict'])
        except Exception as load_error:
            print(f"âš ï¸  åŠ è½½æœ€ä½³æ¨¡å‹å¤±è´¥: {load_error}")

    # æ¸…ç†GPUå†…å­˜
    if device.type == 'cuda':
        torch.cuda.empty_cache()
        log_info("è®­ç»ƒå®Œæˆï¼Œå·²æ¸…ç†GPUå†…å­˜", "SUCCESS")

    return model, train_losses, val_losses


def evaluate_model(model, data_tensor, scaler, device, model_type='standard'):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    if not PYTORCH_AVAILABLE:
        raise ImportError("PyTorchä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œè¯„ä¼°")
        
    model.eval()
    with torch.no_grad():
        if model_type == 'standard':
            recon, latent = model(data_tensor.to(device))
        else:  # VAE
            recon, mu, logvar, latent = model(data_tensor.to(device))
            latent = mu  # ä½¿ç”¨å‡å€¼ä½œä¸ºæ½œåœ¨è¡¨ç¤º

        # è½¬æ¢å›CPUå¹¶è½¬ä¸ºnumpy
        recon = recon.cpu().numpy()
        latent = latent.cpu().numpy()

    # åæ ‡å‡†åŒ–é‡æ„æ•°æ®
    original_data = scaler.inverse_transform(data_tensor.cpu().numpy())
    recon_original = scaler.inverse_transform(recon)

    # è®¡ç®—é‡æ„è¯¯å·®
    mse = mean_squared_error(original_data, recon_original)
    r2 = r2_score(original_data.flatten(), recon_original.flatten())

    return {
        'latent': latent,
        'reconstruction': recon_original,
        'mse': mse,
        'r2': r2
    }